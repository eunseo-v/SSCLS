2023-02-21 15:35:46,203 - pyskl - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Jan 17 2023, 23:13:24) [GCC 11.2.0]
CUDA available: True
GPU 0,1,2,3: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.6, V11.6.55
GCC: gcc (Ubuntu 7.5.0-6ubuntu2) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.7.0
MMCV: 1.6.2
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
pyskl: 0.1.0+HEAD
------------------------------------------------------------

2023-02-21 15:35:47,418 - pyskl - INFO - Config: model = dict(
    type='Recognizer3D',
    backbone=dict(
        type='ResNet3dSlowOnly',
        in_channels=5,
        base_channels=32,
        num_stages=3,
        out_indices=(2, ),
        stage_blocks=(4, 6, 3),
        conv1_stride=(1, 1),
        pool1_stride=(1, 1),
        inflate=(0, 1, 1),
        spatial_strides=(2, 2, 2),
        temporal_strides=(1, 1, 2),
        frozen_stages=3),
    cls_head=dict(
        type='I3DHead', in_channels=512, num_classes=10, dropout=0.5),
    test_cfg=dict(average_clips='prob'))
dataset_type = 'PoseDataset'
ann_file = 'data/ds_taichi/test7nsnr.pkl'
left_kp = [
    5, 6, 7, 8, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,
    60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71
]
right_kp = [
    1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
    32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43
]
train_pipeline = [
    dict(type='UniformSampleFrames', clip_len=48),
    dict(type='PoseDecode'),
    dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
    dict(type='Resize', scale=(-1, 64)),
    dict(type='RandomResizedCrop', area_range=(0.56, 1.0)),
    dict(type='Resize', scale=(56, 56), keep_ratio=False),
    dict(
        type='Flip',
        flip_ratio=0.5,
        left_kp=[
            5, 6, 7, 8, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,
            58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71
        ],
        right_kp=[
            1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,
            30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43
        ]),
    dict(type='GenerateTaiChiPoseTarget', with_kp=True, with_limb=False),
    dict(type='FormatShape', input_format='NCTHW_Heatmap'),
    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
    dict(type='ToTensor', keys=['imgs', 'label'])
]
val_pipeline = [
    dict(type='UniformSampleFrames', clip_len=48, num_clips=1),
    dict(type='PoseDecode'),
    dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
    dict(type='Resize', scale=(64, 64), keep_ratio=False),
    dict(type='GenerateTaiChiPoseTarget', with_kp=True, with_limb=False),
    dict(type='FormatShape', input_format='NCTHW_Heatmap'),
    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
    dict(type='ToTensor', keys=['imgs'])
]
test_pipeline = [
    dict(type='UniformSampleFrames', clip_len=48, num_clips=10),
    dict(type='PoseDecode'),
    dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
    dict(type='Resize', scale=(64, 64), keep_ratio=False),
    dict(
        type='GenerateTaiChiPoseTarget',
        with_kp=True,
        with_limb=False,
        double=True),
    dict(type='FormatShape', input_format='NCTHW_Heatmap'),
    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
    dict(type='ToTensor', keys=['imgs'])
]
data = dict(
    videos_per_gpu=8,
    workers_per_gpu=4,
    test_dataloader=dict(videos_per_gpu=6),
    train=dict(
        type='RepeatDataset',
        times=30,
        dataset=dict(
            type='PoseDataset',
            ann_file='data/ds_taichi/test7nsnr.pkl',
            split='train',
            pipeline=[
                dict(type='UniformSampleFrames', clip_len=48),
                dict(type='PoseDecode'),
                dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
                dict(type='Resize', scale=(-1, 64)),
                dict(type='RandomResizedCrop', area_range=(0.56, 1.0)),
                dict(type='Resize', scale=(56, 56), keep_ratio=False),
                dict(
                    type='Flip',
                    flip_ratio=0.5,
                    left_kp=[
                        5, 6, 7, 8, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,
                        55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,
                        69, 70, 71
                    ],
                    right_kp=[
                        1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,
                        27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,
                        41, 42, 43
                    ]),
                dict(
                    type='GenerateTaiChiPoseTarget',
                    with_kp=True,
                    with_limb=False),
                dict(type='FormatShape', input_format='NCTHW_Heatmap'),
                dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
                dict(type='ToTensor', keys=['imgs', 'label'])
            ])),
    val=dict(
        type='PoseDataset',
        ann_file='data/ds_taichi/test7nsnr.pkl',
        split='test',
        pipeline=[
            dict(type='UniformSampleFrames', clip_len=48, num_clips=1),
            dict(type='PoseDecode'),
            dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
            dict(type='Resize', scale=(64, 64), keep_ratio=False),
            dict(
                type='GenerateTaiChiPoseTarget', with_kp=True,
                with_limb=False),
            dict(type='FormatShape', input_format='NCTHW_Heatmap'),
            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
            dict(type='ToTensor', keys=['imgs'])
        ]),
    test=dict(
        type='PoseDataset',
        ann_file='data/ds_taichi/test7nsnr.pkl',
        split='test',
        pipeline=[
            dict(type='UniformSampleFrames', clip_len=48, num_clips=10),
            dict(type='PoseDecode'),
            dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
            dict(type='Resize', scale=(64, 64), keep_ratio=False),
            dict(
                type='GenerateTaiChiPoseTarget',
                with_kp=True,
                with_limb=False,
                double=True),
            dict(type='FormatShape', input_format='NCTHW_Heatmap'),
            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
            dict(type='ToTensor', keys=['imgs'])
        ]))
optimizer = dict(type='SGD', lr=30, momentum=0.9, weight_decay=0.0003)
optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))
lr_config = dict(policy='CosineAnnealing', by_epoch=False, min_lr=0)
total_epochs = 24
checkpoint_config = dict(interval=24)
evaluation = dict(
    interval=1, metrics=['top_k_accuracy', 'mean_class_accuracy'], topk=(1, 5))
log_config = dict(interval=20, hooks=[dict(type='TextLoggerHook')])
log_level = 'INFO'
output_config = dict(
    out='./model_pth/exp0/t7nsnr_5p_lr30/test_result/results.pkl')
eval_config = dict(
    metric_out='./model_pth/exp0/t7nsnr_5p_lr30/test_result',
    eval=[
        'top_k_accuracy', 'mean_class_accuracy', 'confusion_matrix',
        't_sne_vis'
    ])
work_dir = './model_pth/exp0/t7nsnr_5p_lr30'
load_from = './model_pth/ntu120xsub_5parts_kp/best_top1_acc_epoch_23.pth'
find_unused_parameters = True
dist_params = dict(backend='nccl')
gpu_ids = range(0, 4)

2023-02-21 15:35:47,418 - pyskl - INFO - Set random seed to 42, deterministic: True
2023-02-21 15:35:48,052 - pyskl - INFO - 60 videos remain after valid thresholding
2023-02-21 15:35:53,685 - pyskl - INFO - 140 videos remain after valid thresholding
2023-02-21 15:35:53,686 - pyskl - INFO - load checkpoint from local path: ./model_pth/ntu120xsub_5parts_kp/best_top1_acc_epoch_23.pth
2023-02-21 15:35:53,711 - pyskl - WARNING - The model and loaded state dict do not match exactly

size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([120, 512]) from checkpoint, the shape in current model is torch.Size([10, 512]).
size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([10]).
2023-02-21 15:35:53,711 - pyskl - INFO - Start running, host: yl@83090-jin, work_dir: /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lr30
2023-02-21 15:35:53,712 - pyskl - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(NORMAL      ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) DistEvalHook                       
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) DistEvalHook                       
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) DistEvalHook                       
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-02-21 15:35:53,712 - pyskl - INFO - workflow: [('train', 1)], max: 24 epochs
2023-02-21 15:35:53,712 - pyskl - INFO - Checkpoints will be saved to /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lr30 by HardDiskBackend.
2023-02-21 15:36:11,589 - pyskl - INFO - Epoch [1][20/57]	lr: 2.999e+01, eta: 0:20:04, time: 0.894, data_time: 0.764, memory: 664, top1_acc: 0.1828, top5_acc: 0.6000, loss_cls: 1936.6472, loss: 1936.6472, grad_norm: 7.3059
2023-02-21 15:36:15,179 - pyskl - INFO - Epoch [1][40/57]	lr: 2.994e+01, eta: 0:11:52, time: 0.179, data_time: 0.077, memory: 664, top1_acc: 0.3109, top5_acc: 0.7047, loss_cls: 1288.5864, loss: 1288.5864, grad_norm: 5.5999
2023-02-21 15:36:34,990 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:36:34,991 - pyskl - INFO - 
top1_acc	0.1143
top5_acc	0.4857
2023-02-21 15:36:34,991 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:36:34,991 - pyskl - INFO - 
mean_acc	0.1143
2023-02-21 15:36:35,020 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_1.pth.
2023-02-21 15:36:35,020 - pyskl - INFO - Best top1_acc is 0.1143 at 1 epoch.
2023-02-21 15:36:35,021 - pyskl - INFO - Epoch(val) [1][5]	top1_acc: 0.1143, top5_acc: 0.4857, mean_class_accuracy: 0.1143
2023-02-21 15:36:52,484 - pyskl - INFO - Epoch [2][20/57]	lr: 2.977e+01, eta: 0:10:52, time: 0.873, data_time: 0.816, memory: 861, top1_acc: 0.2578, top5_acc: 0.6578, loss_cls: 1226.4378, loss: 1226.4378, grad_norm: 5.7426
2023-02-21 15:36:56,022 - pyskl - INFO - Epoch [2][40/57]	lr: 2.964e+01, eta: 0:09:16, time: 0.177, data_time: 0.121, memory: 861, top1_acc: 0.2453, top5_acc: 0.6672, loss_cls: 1033.5798, loss: 1033.5798, grad_norm: 5.5545
2023-02-21 15:37:15,762 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:37:15,762 - pyskl - INFO - 
top1_acc	0.2571
top5_acc	0.6857
2023-02-21 15:37:15,762 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:37:15,763 - pyskl - INFO - 
mean_acc	0.2571
2023-02-21 15:37:15,765 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lr30/best_top1_acc_epoch_1.pth was removed
2023-02-21 15:37:15,800 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_2.pth.
2023-02-21 15:37:15,801 - pyskl - INFO - Best top1_acc is 0.2571 at 2 epoch.
2023-02-21 15:37:15,801 - pyskl - INFO - Epoch(val) [2][5]	top1_acc: 0.2571, top5_acc: 0.6857, mean_class_accuracy: 0.2571
2023-02-21 15:37:33,445 - pyskl - INFO - Epoch [3][20/57]	lr: 2.931e+01, eta: 0:09:13, time: 0.882, data_time: 0.833, memory: 861, top1_acc: 0.2531, top5_acc: 0.6859, loss_cls: 1189.6477, loss: 1189.6477, grad_norm: 6.2114
2023-02-21 15:37:36,994 - pyskl - INFO - Epoch [3][40/57]	lr: 2.908e+01, eta: 0:08:21, time: 0.178, data_time: 0.129, memory: 861, top1_acc: 0.2266, top5_acc: 0.6813, loss_cls: 1226.8039, loss: 1226.8039, grad_norm: 6.2982
2023-02-21 15:37:56,698 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:37:56,699 - pyskl - INFO - 
top1_acc	0.3357
top5_acc	0.7429
2023-02-21 15:37:56,699 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:37:56,699 - pyskl - INFO - 
mean_acc	0.3357
2023-02-21 15:37:56,701 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lr30/best_top1_acc_epoch_2.pth was removed
2023-02-21 15:37:56,729 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_3.pth.
2023-02-21 15:37:56,729 - pyskl - INFO - Best top1_acc is 0.3357 at 3 epoch.
2023-02-21 15:37:56,729 - pyskl - INFO - Epoch(val) [3][5]	top1_acc: 0.3357, top5_acc: 0.7429, mean_class_accuracy: 0.3357
2023-02-21 15:38:14,281 - pyskl - INFO - Epoch [4][20/57]	lr: 2.859e+01, eta: 0:08:20, time: 0.877, data_time: 0.730, memory: 861, top1_acc: 0.2719, top5_acc: 0.6937, loss_cls: 931.0047, loss: 931.0047, grad_norm: 5.6976
2023-02-21 15:38:17,830 - pyskl - INFO - Epoch [4][40/57]	lr: 2.829e+01, eta: 0:07:44, time: 0.178, data_time: 0.015, memory: 861, top1_acc: 0.2531, top5_acc: 0.6578, loss_cls: 1005.9641, loss: 1005.9641, grad_norm: 5.7429
2023-02-21 15:38:37,267 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:38:37,268 - pyskl - INFO - 
top1_acc	0.1357
top5_acc	0.5000
2023-02-21 15:38:37,268 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:38:37,268 - pyskl - INFO - 
mean_acc	0.1357
2023-02-21 15:38:37,269 - pyskl - INFO - Epoch(val) [4][5]	top1_acc: 0.1357, top5_acc: 0.5000, mean_class_accuracy: 0.1357
2023-02-21 15:38:54,493 - pyskl - INFO - Epoch [5][20/57]	lr: 2.765e+01, eta: 0:07:40, time: 0.861, data_time: 0.803, memory: 861, top1_acc: 0.2500, top5_acc: 0.6672, loss_cls: 1394.9851, loss: 1394.9851, grad_norm: 5.9993
2023-02-21 15:38:57,889 - pyskl - INFO - Epoch [5][40/57]	lr: 2.727e+01, eta: 0:07:12, time: 0.170, data_time: 0.112, memory: 861, top1_acc: 0.2500, top5_acc: 0.7250, loss_cls: 855.0288, loss: 855.0288, grad_norm: 5.6024
2023-02-21 15:39:17,238 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:39:17,238 - pyskl - INFO - 
top1_acc	0.1786
top5_acc	0.6071
2023-02-21 15:39:17,238 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:39:17,239 - pyskl - INFO - 
mean_acc	0.1786
2023-02-21 15:39:17,239 - pyskl - INFO - Epoch(val) [5][5]	top1_acc: 0.1786, top5_acc: 0.6071, mean_class_accuracy: 0.1786
2023-02-21 15:39:34,627 - pyskl - INFO - Epoch [6][20/57]	lr: 2.649e+01, eta: 0:07:07, time: 0.869, data_time: 0.757, memory: 861, top1_acc: 0.2297, top5_acc: 0.6859, loss_cls: 1108.6827, loss: 1108.6827, grad_norm: 6.1413
2023-02-21 15:39:38,249 - pyskl - INFO - Epoch [6][40/57]	lr: 2.604e+01, eta: 0:06:45, time: 0.181, data_time: 0.034, memory: 861, top1_acc: 0.2812, top5_acc: 0.7188, loss_cls: 950.3004, loss: 950.3004, grad_norm: 5.6044
2023-02-21 15:39:57,766 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:39:57,766 - pyskl - INFO - 
top1_acc	0.4500
top5_acc	0.8500
2023-02-21 15:39:57,766 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:39:57,767 - pyskl - INFO - 
mean_acc	0.4500
2023-02-21 15:39:57,768 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lr30/best_top1_acc_epoch_3.pth was removed
2023-02-21 15:39:57,794 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_6.pth.
2023-02-21 15:39:57,794 - pyskl - INFO - Best top1_acc is 0.4500 at 6 epoch.
2023-02-21 15:39:57,795 - pyskl - INFO - Epoch(val) [6][5]	top1_acc: 0.4500, top5_acc: 0.8500, mean_class_accuracy: 0.4500
2023-02-21 15:40:15,506 - pyskl - INFO - Epoch [7][20/57]	lr: 2.513e+01, eta: 0:06:40, time: 0.885, data_time: 0.726, memory: 861, top1_acc: 0.3172, top5_acc: 0.7172, loss_cls: 905.6720, loss: 905.6720, grad_norm: 5.2398
2023-02-21 15:40:18,967 - pyskl - INFO - Epoch [7][40/57]	lr: 2.462e+01, eta: 0:06:20, time: 0.173, data_time: 0.019, memory: 861, top1_acc: 0.2469, top5_acc: 0.6828, loss_cls: 991.1327, loss: 991.1327, grad_norm: 6.0152
2023-02-21 15:40:38,702 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:40:38,703 - pyskl - INFO - 
top1_acc	0.2857
top5_acc	0.6429
2023-02-21 15:40:38,703 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:40:38,704 - pyskl - INFO - 
mean_acc	0.2857
2023-02-21 15:40:38,704 - pyskl - INFO - Epoch(val) [7][5]	top1_acc: 0.2857, top5_acc: 0.6429, mean_class_accuracy: 0.2857
2023-02-21 15:40:56,331 - pyskl - INFO - Epoch [8][20/57]	lr: 2.360e+01, eta: 0:06:14, time: 0.881, data_time: 0.782, memory: 861, top1_acc: 0.2984, top5_acc: 0.7250, loss_cls: 786.2514, loss: 786.2514, grad_norm: 5.3388
2023-02-21 15:40:59,903 - pyskl - INFO - Epoch [8][40/57]	lr: 2.303e+01, eta: 0:05:57, time: 0.179, data_time: 0.038, memory: 861, top1_acc: 0.2922, top5_acc: 0.7453, loss_cls: 793.7240, loss: 793.7240, grad_norm: 5.6269
2023-02-21 15:41:19,404 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:41:19,405 - pyskl - INFO - 
top1_acc	0.3071
top5_acc	0.6357
2023-02-21 15:41:19,405 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:41:19,406 - pyskl - INFO - 
mean_acc	0.3071
2023-02-21 15:41:19,406 - pyskl - INFO - Epoch(val) [8][5]	top1_acc: 0.3071, top5_acc: 0.6357, mean_class_accuracy: 0.3071
2023-02-21 15:41:36,671 - pyskl - INFO - Epoch [9][20/57]	lr: 2.193e+01, eta: 0:05:48, time: 0.863, data_time: 0.770, memory: 861, top1_acc: 0.2844, top5_acc: 0.7234, loss_cls: 726.0802, loss: 726.0802, grad_norm: 5.4220
2023-02-21 15:41:40,162 - pyskl - INFO - Epoch [9][40/57]	lr: 2.131e+01, eta: 0:05:33, time: 0.175, data_time: 0.101, memory: 861, top1_acc: 0.3750, top5_acc: 0.8094, loss_cls: 412.5628, loss: 412.5628, grad_norm: 4.4418
2023-02-21 15:41:59,466 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:41:59,467 - pyskl - INFO - 
top1_acc	0.2786
top5_acc	0.6214
2023-02-21 15:41:59,467 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:41:59,467 - pyskl - INFO - 
mean_acc	0.2786
2023-02-21 15:41:59,468 - pyskl - INFO - Epoch(val) [9][5]	top1_acc: 0.2786, top5_acc: 0.6214, mean_class_accuracy: 0.2786
2023-02-21 15:42:17,028 - pyskl - INFO - Epoch [10][20/57]	lr: 2.013e+01, eta: 0:05:24, time: 0.878, data_time: 0.826, memory: 861, top1_acc: 0.2781, top5_acc: 0.7000, loss_cls: 727.1565, loss: 727.1565, grad_norm: 5.6133
2023-02-21 15:42:20,522 - pyskl - INFO - Epoch [10][40/57]	lr: 1.948e+01, eta: 0:05:10, time: 0.175, data_time: 0.124, memory: 861, top1_acc: 0.3141, top5_acc: 0.7781, loss_cls: 532.5915, loss: 532.5915, grad_norm: 4.8703
2023-02-21 15:42:39,890 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:42:39,891 - pyskl - INFO - 
top1_acc	0.2000
top5_acc	0.6000
2023-02-21 15:42:39,891 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:42:39,892 - pyskl - INFO - 
mean_acc	0.2000
2023-02-21 15:42:39,892 - pyskl - INFO - Epoch(val) [10][5]	top1_acc: 0.2000, top5_acc: 0.6000, mean_class_accuracy: 0.2000
2023-02-21 15:42:57,543 - pyskl - INFO - Epoch [11][20/57]	lr: 1.825e+01, eta: 0:05:00, time: 0.882, data_time: 0.830, memory: 861, top1_acc: 0.3172, top5_acc: 0.7594, loss_cls: 589.2207, loss: 589.2207, grad_norm: 5.1079
2023-02-21 15:43:01,136 - pyskl - INFO - Epoch [11][40/57]	lr: 1.757e+01, eta: 0:04:48, time: 0.179, data_time: 0.111, memory: 861, top1_acc: 0.3594, top5_acc: 0.8109, loss_cls: 362.2116, loss: 362.2116, grad_norm: 4.4188
2023-02-21 15:43:20,905 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:43:20,906 - pyskl - INFO - 
top1_acc	0.2571
top5_acc	0.5429
2023-02-21 15:43:20,906 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:43:20,906 - pyskl - INFO - 
mean_acc	0.2571
2023-02-21 15:43:20,906 - pyskl - INFO - Epoch(val) [11][5]	top1_acc: 0.2571, top5_acc: 0.5429, mean_class_accuracy: 0.2571
2023-02-21 15:43:38,945 - pyskl - INFO - Epoch [12][20/57]	lr: 1.631e+01, eta: 0:04:38, time: 0.901, data_time: 0.852, memory: 861, top1_acc: 0.3891, top5_acc: 0.7937, loss_cls: 500.3334, loss: 500.3334, grad_norm: 4.3069
2023-02-21 15:43:42,570 - pyskl - INFO - Epoch [12][40/57]	lr: 1.562e+01, eta: 0:04:26, time: 0.181, data_time: 0.132, memory: 861, top1_acc: 0.3266, top5_acc: 0.7844, loss_cls: 424.9092, loss: 424.9092, grad_norm: 4.7649
2023-02-21 15:44:02,087 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:44:02,087 - pyskl - INFO - 
top1_acc	0.2500
top5_acc	0.6143
2023-02-21 15:44:02,088 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:44:02,088 - pyskl - INFO - 
mean_acc	0.2500
2023-02-21 15:44:02,088 - pyskl - INFO - Epoch(val) [12][5]	top1_acc: 0.2500, top5_acc: 0.6143, mean_class_accuracy: 0.2500
2023-02-21 15:44:19,677 - pyskl - INFO - Epoch [13][20/57]	lr: 1.435e+01, eta: 0:04:15, time: 0.879, data_time: 0.823, memory: 861, top1_acc: 0.3000, top5_acc: 0.7312, loss_cls: 517.8565, loss: 517.8565, grad_norm: 5.1693
2023-02-21 15:44:23,293 - pyskl - INFO - Epoch [13][40/57]	lr: 1.366e+01, eta: 0:04:04, time: 0.181, data_time: 0.095, memory: 861, top1_acc: 0.3875, top5_acc: 0.8344, loss_cls: 299.0716, loss: 299.0716, grad_norm: 4.1772
2023-02-21 15:44:42,730 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:44:42,730 - pyskl - INFO - 
top1_acc	0.3786
top5_acc	0.7929
2023-02-21 15:44:42,730 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:44:42,730 - pyskl - INFO - 
mean_acc	0.3786
2023-02-21 15:44:42,731 - pyskl - INFO - Epoch(val) [13][5]	top1_acc: 0.3786, top5_acc: 0.7929, mean_class_accuracy: 0.3786
2023-02-21 15:45:00,245 - pyskl - INFO - Epoch [14][20/57]	lr: 1.240e+01, eta: 0:03:53, time: 0.875, data_time: 0.768, memory: 861, top1_acc: 0.3578, top5_acc: 0.7375, loss_cls: 369.6597, loss: 369.6597, grad_norm: 4.8698
2023-02-21 15:45:03,778 - pyskl - INFO - Epoch [14][40/57]	lr: 1.172e+01, eta: 0:03:42, time: 0.177, data_time: 0.067, memory: 861, top1_acc: 0.3391, top5_acc: 0.7531, loss_cls: 413.0860, loss: 413.0860, grad_norm: 4.9710
2023-02-21 15:45:23,059 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:45:23,060 - pyskl - INFO - 
top1_acc	0.3357
top5_acc	0.6357
2023-02-21 15:45:23,060 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:45:23,061 - pyskl - INFO - 
mean_acc	0.3357
2023-02-21 15:45:23,061 - pyskl - INFO - Epoch(val) [14][5]	top1_acc: 0.3357, top5_acc: 0.6357, mean_class_accuracy: 0.3357
2023-02-21 15:45:40,050 - pyskl - INFO - Epoch [15][20/57]	lr: 1.049e+01, eta: 0:03:30, time: 0.849, data_time: 0.752, memory: 861, top1_acc: 0.3891, top5_acc: 0.7859, loss_cls: 319.5337, loss: 319.5337, grad_norm: 4.4573
2023-02-21 15:45:43,621 - pyskl - INFO - Epoch [15][40/57]	lr: 9.837e+00, eta: 0:03:20, time: 0.179, data_time: 0.036, memory: 861, top1_acc: 0.4031, top5_acc: 0.8125, loss_cls: 245.4608, loss: 245.4608, grad_norm: 4.2626
2023-02-21 15:46:03,405 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:46:03,405 - pyskl - INFO - 
top1_acc	0.4357
top5_acc	0.7143
2023-02-21 15:46:03,405 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:46:03,406 - pyskl - INFO - 
mean_acc	0.4357
2023-02-21 15:46:03,406 - pyskl - INFO - Epoch(val) [15][5]	top1_acc: 0.4357, top5_acc: 0.7143, mean_class_accuracy: 0.4357
2023-02-21 15:46:21,146 - pyskl - INFO - Epoch [16][20/57]	lr: 8.661e+00, eta: 0:03:08, time: 0.887, data_time: 0.819, memory: 861, top1_acc: 0.3922, top5_acc: 0.8063, loss_cls: 258.7376, loss: 258.7376, grad_norm: 4.2434
2023-02-21 15:46:24,719 - pyskl - INFO - Epoch [16][40/57]	lr: 8.043e+00, eta: 0:02:58, time: 0.178, data_time: 0.080, memory: 861, top1_acc: 0.3531, top5_acc: 0.8391, loss_cls: 209.1561, loss: 209.1561, grad_norm: 4.4208
2023-02-21 15:46:44,522 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:46:44,523 - pyskl - INFO - 
top1_acc	0.7429
top5_acc	0.9357
2023-02-21 15:46:44,523 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:46:44,523 - pyskl - INFO - 
mean_acc	0.7429
2023-02-21 15:46:44,525 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lr30/best_top1_acc_epoch_6.pth was removed
2023-02-21 15:46:44,554 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_16.pth.
2023-02-21 15:46:44,554 - pyskl - INFO - Best top1_acc is 0.7429 at 16 epoch.
2023-02-21 15:46:44,555 - pyskl - INFO - Epoch(val) [16][5]	top1_acc: 0.7429, top5_acc: 0.9357, mean_class_accuracy: 0.7429
2023-02-21 15:47:02,310 - pyskl - INFO - Epoch [17][20/57]	lr: 6.941e+00, eta: 0:02:46, time: 0.888, data_time: 0.797, memory: 861, top1_acc: 0.4188, top5_acc: 0.8844, loss_cls: 160.9673, loss: 160.9673, grad_norm: 4.0390
2023-02-21 15:47:05,907 - pyskl - INFO - Epoch [17][40/57]	lr: 6.368e+00, eta: 0:02:36, time: 0.180, data_time: 0.063, memory: 861, top1_acc: 0.4359, top5_acc: 0.8547, loss_cls: 166.1953, loss: 166.1953, grad_norm: 4.2495
2023-02-21 15:47:25,629 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:47:25,629 - pyskl - INFO - 
top1_acc	0.5071
top5_acc	0.8357
2023-02-21 15:47:25,629 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:47:25,629 - pyskl - INFO - 
mean_acc	0.5071
2023-02-21 15:47:25,630 - pyskl - INFO - Epoch(val) [17][5]	top1_acc: 0.5071, top5_acc: 0.8357, mean_class_accuracy: 0.5071
2023-02-21 15:47:43,174 - pyskl - INFO - Epoch [18][20/57]	lr: 5.358e+00, eta: 0:02:24, time: 0.877, data_time: 0.800, memory: 861, top1_acc: 0.4094, top5_acc: 0.8422, loss_cls: 172.7362, loss: 172.7362, grad_norm: 4.5393
2023-02-21 15:47:46,924 - pyskl - INFO - Epoch [18][40/57]	lr: 4.841e+00, eta: 0:02:15, time: 0.187, data_time: 0.115, memory: 861, top1_acc: 0.5031, top5_acc: 0.8984, loss_cls: 110.7378, loss: 110.7378, grad_norm: 3.4776
2023-02-21 15:48:06,939 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:48:06,940 - pyskl - INFO - 
top1_acc	0.6071
top5_acc	0.9429
2023-02-21 15:48:06,940 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:48:06,940 - pyskl - INFO - 
mean_acc	0.6071
2023-02-21 15:48:06,940 - pyskl - INFO - Epoch(val) [18][5]	top1_acc: 0.6071, top5_acc: 0.9429, mean_class_accuracy: 0.6071
2023-02-21 15:48:24,807 - pyskl - INFO - Epoch [19][20/57]	lr: 3.941e+00, eta: 0:02:02, time: 0.893, data_time: 0.843, memory: 861, top1_acc: 0.5422, top5_acc: 0.9156, loss_cls: 77.3212, loss: 77.3212, grad_norm: 3.3110
2023-02-21 15:48:28,385 - pyskl - INFO - Epoch [19][40/57]	lr: 3.487e+00, eta: 0:01:53, time: 0.179, data_time: 0.127, memory: 861, top1_acc: 0.5156, top5_acc: 0.8922, loss_cls: 84.9537, loss: 84.9537, grad_norm: 3.6854
2023-02-21 15:48:48,257 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:48:48,258 - pyskl - INFO - 
top1_acc	0.6571
top5_acc	0.9571
2023-02-21 15:48:48,258 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:48:48,258 - pyskl - INFO - 
mean_acc	0.6571
2023-02-21 15:48:48,258 - pyskl - INFO - Epoch(val) [19][5]	top1_acc: 0.6571, top5_acc: 0.9571, mean_class_accuracy: 0.6571
2023-02-21 15:49:06,073 - pyskl - INFO - Epoch [20][20/57]	lr: 2.713e+00, eta: 0:01:40, time: 0.890, data_time: 0.840, memory: 861, top1_acc: 0.5312, top5_acc: 0.9391, loss_cls: 61.9870, loss: 61.9870, grad_norm: 3.5253
2023-02-21 15:49:09,662 - pyskl - INFO - Epoch [20][40/57]	lr: 2.331e+00, eta: 0:01:32, time: 0.180, data_time: 0.130, memory: 861, top1_acc: 0.5719, top5_acc: 0.9453, loss_cls: 46.4840, loss: 46.4840, grad_norm: 3.1636
2023-02-21 15:49:29,452 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:49:29,453 - pyskl - INFO - 
top1_acc	0.5786
top5_acc	0.9786
2023-02-21 15:49:29,453 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:49:29,454 - pyskl - INFO - 
mean_acc	0.5786
2023-02-21 15:49:29,454 - pyskl - INFO - Epoch(val) [20][5]	top1_acc: 0.5786, top5_acc: 0.9786, mean_class_accuracy: 0.5786
2023-02-21 15:49:47,236 - pyskl - INFO - Epoch [21][20/57]	lr: 1.695e+00, eta: 0:01:19, time: 0.889, data_time: 0.755, memory: 861, top1_acc: 0.5875, top5_acc: 0.9266, loss_cls: 40.3923, loss: 40.3923, grad_norm: 3.3126
2023-02-21 15:49:50,825 - pyskl - INFO - Epoch [21][40/57]	lr: 1.391e+00, eta: 0:01:10, time: 0.179, data_time: 0.027, memory: 861, top1_acc: 0.6234, top5_acc: 0.9578, loss_cls: 31.6511, loss: 31.6511, grad_norm: 2.7628
2023-02-21 15:50:10,711 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:50:10,711 - pyskl - INFO - 
top1_acc	0.8214
top5_acc	1.0000
2023-02-21 15:50:10,711 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:50:10,712 - pyskl - INFO - 
mean_acc	0.8214
2023-02-21 15:50:10,713 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lr30/best_top1_acc_epoch_16.pth was removed
2023-02-21 15:50:10,739 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_21.pth.
2023-02-21 15:50:10,739 - pyskl - INFO - Best top1_acc is 0.8214 at 21 epoch.
2023-02-21 15:50:10,739 - pyskl - INFO - Epoch(val) [21][5]	top1_acc: 0.8214, top5_acc: 1.0000, mean_class_accuracy: 0.8214
2023-02-21 15:50:28,666 - pyskl - INFO - Epoch [22][20/57]	lr: 9.046e-01, eta: 0:00:57, time: 0.896, data_time: 0.737, memory: 861, top1_acc: 0.6766, top5_acc: 0.9641, loss_cls: 22.3865, loss: 22.3865, grad_norm: 2.3924
2023-02-21 15:50:32,191 - pyskl - INFO - Epoch [22][40/57]	lr: 6.839e-01, eta: 0:00:49, time: 0.176, data_time: 0.000, memory: 861, top1_acc: 0.7234, top5_acc: 0.9875, loss_cls: 14.7543, loss: 14.7543, grad_norm: 2.1896
2023-02-21 15:50:52,063 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:50:52,064 - pyskl - INFO - 
top1_acc	0.8500
top5_acc	1.0000
2023-02-21 15:50:52,064 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:50:52,064 - pyskl - INFO - 
mean_acc	0.8500
2023-02-21 15:50:52,066 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lr30/best_top1_acc_epoch_21.pth was removed
2023-02-21 15:50:52,093 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_22.pth.
2023-02-21 15:50:52,094 - pyskl - INFO - Best top1_acc is 0.8500 at 22 epoch.
2023-02-21 15:50:52,094 - pyskl - INFO - Epoch(val) [22][5]	top1_acc: 0.8500, top5_acc: 1.0000, mean_class_accuracy: 0.8500
2023-02-21 15:51:09,891 - pyskl - INFO - Epoch [23][20/57]	lr: 3.556e-01, eta: 0:00:35, time: 0.889, data_time: 0.840, memory: 861, top1_acc: 0.7422, top5_acc: 0.9922, loss_cls: 10.2045, loss: 10.2045, grad_norm: 1.9732
2023-02-21 15:51:13,469 - pyskl - INFO - Epoch [23][40/57]	lr: 2.219e-01, eta: 0:00:27, time: 0.179, data_time: 0.128, memory: 861, top1_acc: 0.7766, top5_acc: 0.9844, loss_cls: 9.5528, loss: 9.5528, grad_norm: 1.7736
2023-02-21 15:51:33,210 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:51:33,210 - pyskl - INFO - 
top1_acc	0.9143
top5_acc	1.0000
2023-02-21 15:51:33,210 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:51:33,211 - pyskl - INFO - 
mean_acc	0.9143
2023-02-21 15:51:33,213 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lr30/best_top1_acc_epoch_22.pth was removed
2023-02-21 15:51:33,244 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_23.pth.
2023-02-21 15:51:33,245 - pyskl - INFO - Best top1_acc is 0.9143 at 23 epoch.
2023-02-21 15:51:33,245 - pyskl - INFO - Epoch(val) [23][5]	top1_acc: 0.9143, top5_acc: 1.0000, mean_class_accuracy: 0.9143
2023-02-21 15:51:51,185 - pyskl - INFO - Epoch [24][20/57]	lr: 5.708e-02, eta: 0:00:14, time: 0.897, data_time: 0.847, memory: 861, top1_acc: 0.7984, top5_acc: 0.9906, loss_cls: 7.9163, loss: 7.9163, grad_norm: 1.6553
2023-02-21 15:51:54,847 - pyskl - INFO - Epoch [24][40/57]	lr: 1.281e-02, eta: 0:00:06, time: 0.183, data_time: 0.119, memory: 861, top1_acc: 0.7734, top5_acc: 0.9891, loss_cls: 9.5616, loss: 9.5616, grad_norm: 1.8443
2023-02-21 15:51:58,439 - pyskl - INFO - Saving checkpoint at 24 epochs
2023-02-21 15:52:14,682 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 15:52:14,683 - pyskl - INFO - 
top1_acc	0.9714
top5_acc	1.0000
2023-02-21 15:52:14,683 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 15:52:14,683 - pyskl - INFO - 
mean_acc	0.9714
2023-02-21 15:52:14,685 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lr30/best_top1_acc_epoch_23.pth was removed
2023-02-21 15:52:14,712 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_24.pth.
2023-02-21 15:52:14,713 - pyskl - INFO - Best top1_acc is 0.9714 at 24 epoch.
2023-02-21 15:52:14,713 - pyskl - INFO - Epoch(val) [24][5]	top1_acc: 0.9714, top5_acc: 1.0000, mean_class_accuracy: 0.9714
