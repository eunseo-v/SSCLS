2023-02-21 16:26:02,624 - pyskl - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Jan 17 2023, 23:13:24) [GCC 11.2.0]
CUDA available: True
GPU 0,1,2,3: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.6, V11.6.55
GCC: gcc (Ubuntu 7.5.0-6ubuntu2) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.7.0
MMCV: 1.6.2
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
pyskl: 0.1.0+HEAD
------------------------------------------------------------

2023-02-21 16:26:04,177 - pyskl - INFO - Config: model = dict(
    type='Recognizer3D',
    backbone=dict(
        type='ResNet3dSlowOnly',
        in_channels=5,
        base_channels=32,
        num_stages=3,
        out_indices=(2, ),
        stage_blocks=(4, 6, 3),
        conv1_stride=(1, 1),
        pool1_stride=(1, 1),
        inflate=(0, 1, 1),
        spatial_strides=(2, 2, 2),
        temporal_strides=(1, 1, 2),
        frozen_stages=3),
    cls_head=dict(
        type='I3DHead', in_channels=512, num_classes=10, dropout=0.5),
    test_cfg=dict(average_clips='prob'))
dataset_type = 'PoseDataset'
ann_file = 'data/ds_taichi/test7nsnr.pkl'
left_kp = [
    5, 6, 7, 8, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,
    60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71
]
right_kp = [
    1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
    32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43
]
train_pipeline = [
    dict(type='UniformSampleFrames', clip_len=48),
    dict(type='PoseDecode'),
    dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
    dict(type='Resize', scale=(-1, 64)),
    dict(type='RandomResizedCrop', area_range=(0.56, 1.0)),
    dict(type='Resize', scale=(56, 56), keep_ratio=False),
    dict(
        type='Flip',
        flip_ratio=0.5,
        left_kp=[
            5, 6, 7, 8, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,
            58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71
        ],
        right_kp=[
            1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,
            30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43
        ]),
    dict(type='GenerateTaiChiPoseTarget', with_kp=True, with_limb=False),
    dict(type='FormatShape', input_format='NCTHW_Heatmap'),
    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
    dict(type='ToTensor', keys=['imgs', 'label'])
]
val_pipeline = [
    dict(type='UniformSampleFrames', clip_len=48, num_clips=1),
    dict(type='PoseDecode'),
    dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
    dict(type='Resize', scale=(64, 64), keep_ratio=False),
    dict(type='GenerateTaiChiPoseTarget', with_kp=True, with_limb=False),
    dict(type='FormatShape', input_format='NCTHW_Heatmap'),
    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
    dict(type='ToTensor', keys=['imgs'])
]
test_pipeline = [
    dict(type='UniformSampleFrames', clip_len=48, num_clips=10),
    dict(type='PoseDecode'),
    dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
    dict(type='Resize', scale=(64, 64), keep_ratio=False),
    dict(
        type='GenerateTaiChiPoseTarget',
        with_kp=True,
        with_limb=False,
        double=True),
    dict(type='FormatShape', input_format='NCTHW_Heatmap'),
    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
    dict(type='ToTensor', keys=['imgs'])
]
data = dict(
    videos_per_gpu=8,
    workers_per_gpu=4,
    test_dataloader=dict(videos_per_gpu=6),
    train=dict(
        type='RepeatDataset',
        times=30,
        dataset=dict(
            type='PoseDataset',
            ann_file='data/ds_taichi/test7nsnr.pkl',
            split='train',
            pipeline=[
                dict(type='UniformSampleFrames', clip_len=48),
                dict(type='PoseDecode'),
                dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
                dict(type='Resize', scale=(-1, 64)),
                dict(type='RandomResizedCrop', area_range=(0.56, 1.0)),
                dict(type='Resize', scale=(56, 56), keep_ratio=False),
                dict(
                    type='Flip',
                    flip_ratio=0.5,
                    left_kp=[
                        5, 6, 7, 8, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,
                        55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,
                        69, 70, 71
                    ],
                    right_kp=[
                        1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,
                        27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,
                        41, 42, 43
                    ]),
                dict(
                    type='GenerateTaiChiPoseTarget',
                    with_kp=True,
                    with_limb=False),
                dict(type='FormatShape', input_format='NCTHW_Heatmap'),
                dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
                dict(type='ToTensor', keys=['imgs', 'label'])
            ])),
    val=dict(
        type='PoseDataset',
        ann_file='data/ds_taichi/test7nsnr.pkl',
        split='test',
        pipeline=[
            dict(type='UniformSampleFrames', clip_len=48, num_clips=1),
            dict(type='PoseDecode'),
            dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
            dict(type='Resize', scale=(64, 64), keep_ratio=False),
            dict(
                type='GenerateTaiChiPoseTarget', with_kp=True,
                with_limb=False),
            dict(type='FormatShape', input_format='NCTHW_Heatmap'),
            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
            dict(type='ToTensor', keys=['imgs'])
        ]),
    test=dict(
        type='PoseDataset',
        ann_file='data/ds_taichi/test7nsnr.pkl',
        split='test',
        pipeline=[
            dict(type='UniformSampleFrames', clip_len=48, num_clips=10),
            dict(type='PoseDecode'),
            dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
            dict(type='Resize', scale=(64, 64), keep_ratio=False),
            dict(
                type='GenerateTaiChiPoseTarget',
                with_kp=True,
                with_limb=False,
                double=True),
            dict(type='FormatShape', input_format='NCTHW_Heatmap'),
            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
            dict(type='ToTensor', keys=['imgs'])
        ]))
optimizer = dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0003)
optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))
lr_config = dict(policy='CosineAnnealing', by_epoch=False, min_lr=0)
total_epochs = 24
checkpoint_config = dict(interval=24)
evaluation = dict(
    interval=1, metrics=['top_k_accuracy', 'mean_class_accuracy'], topk=(1, 5))
log_config = dict(interval=20, hooks=[dict(type='TextLoggerHook')])
log_level = 'INFO'
output_config = dict(
    out='./model_pth/exp0/t7nsnr_5p_lrd1/test_result/results.pkl')
eval_config = dict(
    metric_out='./model_pth/exp0/t7nsnr_5p_lrd1/test_result',
    eval=[
        'top_k_accuracy', 'mean_class_accuracy', 'confusion_matrix',
        't_sne_vis'
    ])
work_dir = './model_pth/exp0/t7nsnr_5p_lrd1'
load_from = './model_pth/ntu120xsub_5parts_kp/best_top1_acc_epoch_23.pth'
find_unused_parameters = True
dist_params = dict(backend='nccl')
gpu_ids = range(0, 4)

2023-02-21 16:26:04,177 - pyskl - INFO - Set random seed to 42, deterministic: True
2023-02-21 16:26:04,844 - pyskl - INFO - 60 videos remain after valid thresholding
2023-02-21 16:26:10,093 - pyskl - INFO - 140 videos remain after valid thresholding
2023-02-21 16:26:10,094 - pyskl - INFO - load checkpoint from local path: ./model_pth/ntu120xsub_5parts_kp/best_top1_acc_epoch_23.pth
2023-02-21 16:26:10,117 - pyskl - WARNING - The model and loaded state dict do not match exactly

size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([120, 512]) from checkpoint, the shape in current model is torch.Size([10, 512]).
size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([10]).
2023-02-21 16:26:10,117 - pyskl - INFO - Start running, host: yl@83090-jin, work_dir: /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lrd1
2023-02-21 16:26:10,117 - pyskl - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(NORMAL      ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) DistEvalHook                       
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) DistEvalHook                       
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) DistEvalHook                       
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-02-21 16:26:10,118 - pyskl - INFO - workflow: [('train', 1)], max: 24 epochs
2023-02-21 16:26:10,118 - pyskl - INFO - Checkpoints will be saved to /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lrd1 by HardDiskBackend.
2023-02-21 16:26:28,037 - pyskl - INFO - Epoch [1][20/57]	lr: 9.995e-02, eta: 0:20:07, time: 0.896, data_time: 0.786, memory: 664, top1_acc: 0.2781, top5_acc: 0.7469, loss_cls: 2.0767, loss: 2.0767, grad_norm: 3.3297
2023-02-21 16:26:31,732 - pyskl - INFO - Epoch [1][40/57]	lr: 9.980e-02, eta: 0:11:57, time: 0.185, data_time: 0.077, memory: 664, top1_acc: 0.4594, top5_acc: 0.9047, loss_cls: 1.9732, loss: 1.9732, grad_norm: 3.4170
2023-02-21 16:26:51,605 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:26:51,605 - pyskl - INFO - 
top1_acc	0.6214
top5_acc	0.8929
2023-02-21 16:26:51,605 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:26:51,605 - pyskl - INFO - 
mean_acc	0.6214
2023-02-21 16:26:51,633 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_1.pth.
2023-02-21 16:26:51,633 - pyskl - INFO - Best top1_acc is 0.6214 at 1 epoch.
2023-02-21 16:26:51,634 - pyskl - INFO - Epoch(val) [1][5]	top1_acc: 0.6214, top5_acc: 0.8929, mean_class_accuracy: 0.6214
2023-02-21 16:27:09,471 - pyskl - INFO - Epoch [2][20/57]	lr: 9.924e-02, eta: 0:11:01, time: 0.892, data_time: 0.844, memory: 861, top1_acc: 0.5656, top5_acc: 0.9203, loss_cls: 1.6386, loss: 1.6386, grad_norm: 2.8136
2023-02-21 16:27:13,040 - pyskl - INFO - Epoch [2][40/57]	lr: 9.879e-02, eta: 0:09:23, time: 0.178, data_time: 0.107, memory: 861, top1_acc: 0.5891, top5_acc: 0.9469, loss_cls: 1.7015, loss: 1.7015, grad_norm: 2.6853
2023-02-21 16:27:32,841 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:27:32,842 - pyskl - INFO - 
top1_acc	0.6000
top5_acc	0.9429
2023-02-21 16:27:32,842 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:27:32,844 - pyskl - INFO - 
mean_acc	0.6000
2023-02-21 16:27:32,844 - pyskl - INFO - Epoch(val) [2][5]	top1_acc: 0.6000, top5_acc: 0.9429, mean_class_accuracy: 0.6000
2023-02-21 16:27:50,435 - pyskl - INFO - Epoch [3][20/57]	lr: 9.769e-02, eta: 0:09:18, time: 0.879, data_time: 0.821, memory: 861, top1_acc: 0.6391, top5_acc: 0.9563, loss_cls: 1.5942, loss: 1.5942, grad_norm: 2.6588
2023-02-21 16:27:54,048 - pyskl - INFO - Epoch [3][40/57]	lr: 9.695e-02, eta: 0:08:26, time: 0.181, data_time: 0.132, memory: 861, top1_acc: 0.6188, top5_acc: 0.9656, loss_cls: 1.6467, loss: 1.6467, grad_norm: 2.8120
2023-02-21 16:28:13,979 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:28:13,980 - pyskl - INFO - 
top1_acc	0.7714
top5_acc	0.9857
2023-02-21 16:28:13,980 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:28:13,981 - pyskl - INFO - 
mean_acc	0.7714
2023-02-21 16:28:13,983 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lrd1/best_top1_acc_epoch_1.pth was removed
2023-02-21 16:28:14,012 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_3.pth.
2023-02-21 16:28:14,012 - pyskl - INFO - Best top1_acc is 0.7714 at 3 epoch.
2023-02-21 16:28:14,012 - pyskl - INFO - Epoch(val) [3][5]	top1_acc: 0.7714, top5_acc: 0.9857, mean_class_accuracy: 0.7714
2023-02-21 16:28:31,750 - pyskl - INFO - Epoch [4][20/57]	lr: 9.532e-02, eta: 0:08:24, time: 0.887, data_time: 0.839, memory: 861, top1_acc: 0.7016, top5_acc: 0.9766, loss_cls: 1.2906, loss: 1.2906, grad_norm: 2.3459
2023-02-21 16:28:35,409 - pyskl - INFO - Epoch [4][40/57]	lr: 9.430e-02, eta: 0:07:49, time: 0.183, data_time: 0.135, memory: 861, top1_acc: 0.6844, top5_acc: 0.9672, loss_cls: 1.5780, loss: 1.5780, grad_norm: 2.4459
2023-02-21 16:28:55,069 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:28:55,070 - pyskl - INFO - 
top1_acc	0.7714
top5_acc	0.9643
2023-02-21 16:28:55,070 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:28:55,071 - pyskl - INFO - 
mean_acc	0.7714
2023-02-21 16:28:55,071 - pyskl - INFO - Epoch(val) [4][5]	top1_acc: 0.7714, top5_acc: 0.9643, mean_class_accuracy: 0.7714
2023-02-21 16:29:12,959 - pyskl - INFO - Epoch [5][20/57]	lr: 9.217e-02, eta: 0:07:47, time: 0.894, data_time: 0.794, memory: 861, top1_acc: 0.7406, top5_acc: 0.9844, loss_cls: 1.0392, loss: 1.0392, grad_norm: 1.9033
2023-02-21 16:29:16,613 - pyskl - INFO - Epoch [5][40/57]	lr: 9.089e-02, eta: 0:07:19, time: 0.183, data_time: 0.055, memory: 861, top1_acc: 0.7484, top5_acc: 0.9828, loss_cls: 0.9912, loss: 0.9912, grad_norm: 1.8771
2023-02-21 16:29:36,271 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:29:36,271 - pyskl - INFO - 
top1_acc	0.8857
top5_acc	0.9929
2023-02-21 16:29:36,271 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:29:36,272 - pyskl - INFO - 
mean_acc	0.8857
2023-02-21 16:29:36,273 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lrd1/best_top1_acc_epoch_3.pth was removed
2023-02-21 16:29:36,300 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_5.pth.
2023-02-21 16:29:36,301 - pyskl - INFO - Best top1_acc is 0.8857 at 5 epoch.
2023-02-21 16:29:36,301 - pyskl - INFO - Epoch(val) [5][5]	top1_acc: 0.8857, top5_acc: 0.9929, mean_class_accuracy: 0.8857
2023-02-21 16:29:53,818 - pyskl - INFO - Epoch [6][20/57]	lr: 8.830e-02, eta: 0:07:14, time: 0.876, data_time: 0.785, memory: 861, top1_acc: 0.7391, top5_acc: 0.9766, loss_cls: 1.0359, loss: 1.0359, grad_norm: 1.8996
2023-02-21 16:29:57,384 - pyskl - INFO - Epoch [6][40/57]	lr: 8.679e-02, eta: 0:06:51, time: 0.178, data_time: 0.061, memory: 861, top1_acc: 0.7625, top5_acc: 0.9969, loss_cls: 0.8637, loss: 0.8637, grad_norm: 1.8212
2023-02-21 16:30:17,260 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:30:17,261 - pyskl - INFO - 
top1_acc	0.9143
top5_acc	1.0000
2023-02-21 16:30:17,261 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:30:17,261 - pyskl - INFO - 
mean_acc	0.9143
2023-02-21 16:30:17,263 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lrd1/best_top1_acc_epoch_5.pth was removed
2023-02-21 16:30:17,290 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_6.pth.
2023-02-21 16:30:17,290 - pyskl - INFO - Best top1_acc is 0.9143 at 6 epoch.
2023-02-21 16:30:17,291 - pyskl - INFO - Epoch(val) [6][5]	top1_acc: 0.9143, top5_acc: 1.0000, mean_class_accuracy: 0.9143
2023-02-21 16:30:35,063 - pyskl - INFO - Epoch [7][20/57]	lr: 8.378e-02, eta: 0:06:45, time: 0.888, data_time: 0.836, memory: 861, top1_acc: 0.7688, top5_acc: 0.9891, loss_cls: 0.8725, loss: 0.8725, grad_norm: 1.8249
2023-02-21 16:30:38,531 - pyskl - INFO - Epoch [7][40/57]	lr: 8.205e-02, eta: 0:06:25, time: 0.173, data_time: 0.122, memory: 861, top1_acc: 0.7469, top5_acc: 0.9906, loss_cls: 0.9257, loss: 0.9257, grad_norm: 1.9542
2023-02-21 16:30:58,194 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:30:58,195 - pyskl - INFO - 
top1_acc	0.8143
top5_acc	0.9929
2023-02-21 16:30:58,195 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:30:58,195 - pyskl - INFO - 
mean_acc	0.8143
2023-02-21 16:30:58,195 - pyskl - INFO - Epoch(val) [7][5]	top1_acc: 0.8143, top5_acc: 0.9929, mean_class_accuracy: 0.8143
2023-02-21 16:31:16,174 - pyskl - INFO - Epoch [8][20/57]	lr: 7.868e-02, eta: 0:06:19, time: 0.899, data_time: 0.812, memory: 861, top1_acc: 0.7500, top5_acc: 0.9969, loss_cls: 0.9668, loss: 0.9668, grad_norm: 2.0254
2023-02-21 16:31:19,883 - pyskl - INFO - Epoch [8][40/57]	lr: 7.677e-02, eta: 0:06:02, time: 0.185, data_time: 0.043, memory: 861, top1_acc: 0.8016, top5_acc: 0.9953, loss_cls: 0.7388, loss: 0.7388, grad_norm: 1.6164
2023-02-21 16:31:39,624 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:31:39,625 - pyskl - INFO - 
top1_acc	0.8071
top5_acc	0.9500
2023-02-21 16:31:39,625 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:31:39,625 - pyskl - INFO - 
mean_acc	0.8071
2023-02-21 16:31:39,626 - pyskl - INFO - Epoch(val) [8][5]	top1_acc: 0.8071, top5_acc: 0.9500, mean_class_accuracy: 0.8071
2023-02-21 16:31:57,651 - pyskl - INFO - Epoch [9][20/57]	lr: 7.309e-02, eta: 0:05:54, time: 0.901, data_time: 0.716, memory: 861, top1_acc: 0.7953, top5_acc: 0.9859, loss_cls: 0.7703, loss: 0.7703, grad_norm: 1.7267
2023-02-21 16:32:01,168 - pyskl - INFO - Epoch [9][40/57]	lr: 7.103e-02, eta: 0:05:38, time: 0.176, data_time: 0.000, memory: 861, top1_acc: 0.8016, top5_acc: 0.9953, loss_cls: 0.7046, loss: 0.7046, grad_norm: 1.6692
2023-02-21 16:32:21,142 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:32:21,142 - pyskl - INFO - 
top1_acc	0.9000
top5_acc	0.9929
2023-02-21 16:32:21,142 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:32:21,143 - pyskl - INFO - 
mean_acc	0.9000
2023-02-21 16:32:21,143 - pyskl - INFO - Epoch(val) [9][5]	top1_acc: 0.9000, top5_acc: 0.9929, mean_class_accuracy: 0.9000
2023-02-21 16:32:39,323 - pyskl - INFO - Epoch [10][20/57]	lr: 6.710e-02, eta: 0:05:30, time: 0.908, data_time: 0.727, memory: 861, top1_acc: 0.8344, top5_acc: 0.9953, loss_cls: 0.5393, loss: 0.5393, grad_norm: 1.4066
2023-02-21 16:32:42,854 - pyskl - INFO - Epoch [10][40/57]	lr: 6.493e-02, eta: 0:05:15, time: 0.177, data_time: 0.004, memory: 861, top1_acc: 0.8016, top5_acc: 0.9906, loss_cls: 0.7887, loss: 0.7887, grad_norm: 1.5916
2023-02-21 16:33:03,056 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:33:03,056 - pyskl - INFO - 
top1_acc	0.9000
top5_acc	1.0000
2023-02-21 16:33:03,056 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:33:03,057 - pyskl - INFO - 
mean_acc	0.9000
2023-02-21 16:33:03,057 - pyskl - INFO - Epoch(val) [10][5]	top1_acc: 0.9000, top5_acc: 1.0000, mean_class_accuracy: 0.9000
2023-02-21 16:33:20,802 - pyskl - INFO - Epoch [11][20/57]	lr: 6.082e-02, eta: 0:05:06, time: 0.887, data_time: 0.791, memory: 861, top1_acc: 0.8141, top5_acc: 0.9875, loss_cls: 0.7407, loss: 0.7407, grad_norm: 1.6173
2023-02-21 16:33:24,253 - pyskl - INFO - Epoch [11][40/57]	lr: 5.857e-02, eta: 0:04:52, time: 0.173, data_time: 0.092, memory: 861, top1_acc: 0.8141, top5_acc: 0.9969, loss_cls: 0.6237, loss: 0.6237, grad_norm: 1.5295
2023-02-21 16:33:44,108 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:33:44,109 - pyskl - INFO - 
top1_acc	0.9429
top5_acc	1.0000
2023-02-21 16:33:44,109 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:33:44,110 - pyskl - INFO - 
mean_acc	0.9429
2023-02-21 16:33:44,113 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lrd1/best_top1_acc_epoch_6.pth was removed
2023-02-21 16:33:44,144 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_11.pth.
2023-02-21 16:33:44,144 - pyskl - INFO - Best top1_acc is 0.9429 at 11 epoch.
2023-02-21 16:33:44,144 - pyskl - INFO - Epoch(val) [11][5]	top1_acc: 0.9429, top5_acc: 1.0000, mean_class_accuracy: 0.9429
2023-02-21 16:34:01,987 - pyskl - INFO - Epoch [12][20/57]	lr: 5.436e-02, eta: 0:04:42, time: 0.892, data_time: 0.776, memory: 861, top1_acc: 0.8219, top5_acc: 0.9922, loss_cls: 0.6148, loss: 0.6148, grad_norm: 1.5205
2023-02-21 16:34:05,602 - pyskl - INFO - Epoch [12][40/57]	lr: 5.207e-02, eta: 0:04:30, time: 0.181, data_time: 0.035, memory: 861, top1_acc: 0.8531, top5_acc: 0.9922, loss_cls: 0.5339, loss: 0.5339, grad_norm: 1.3481
2023-02-21 16:34:25,628 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:34:25,628 - pyskl - INFO - 
top1_acc	0.9071
top5_acc	1.0000
2023-02-21 16:34:25,628 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:34:25,629 - pyskl - INFO - 
mean_acc	0.9071
2023-02-21 16:34:25,629 - pyskl - INFO - Epoch(val) [12][5]	top1_acc: 0.9071, top5_acc: 1.0000, mean_class_accuracy: 0.9071
2023-02-21 16:34:43,569 - pyskl - INFO - Epoch [13][20/57]	lr: 4.782e-02, eta: 0:04:19, time: 0.897, data_time: 0.729, memory: 861, top1_acc: 0.8422, top5_acc: 0.9922, loss_cls: 0.5423, loss: 0.5423, grad_norm: 1.3927
2023-02-21 16:34:47,114 - pyskl - INFO - Epoch [13][40/57]	lr: 4.553e-02, eta: 0:04:07, time: 0.177, data_time: 0.037, memory: 861, top1_acc: 0.8234, top5_acc: 0.9906, loss_cls: 0.5366, loss: 0.5366, grad_norm: 1.4074
2023-02-21 16:35:07,018 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:35:07,018 - pyskl - INFO - 
top1_acc	0.9429
top5_acc	1.0000
2023-02-21 16:35:07,018 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:35:07,019 - pyskl - INFO - 
mean_acc	0.9429
2023-02-21 16:35:07,019 - pyskl - INFO - Epoch(val) [13][5]	top1_acc: 0.9429, top5_acc: 1.0000, mean_class_accuracy: 0.9429
2023-02-21 16:35:24,689 - pyskl - INFO - Epoch [14][20/57]	lr: 4.132e-02, eta: 0:03:56, time: 0.883, data_time: 0.829, memory: 861, top1_acc: 0.8484, top5_acc: 0.9969, loss_cls: 0.4796, loss: 0.4796, grad_norm: 1.3854
2023-02-21 16:35:28,239 - pyskl - INFO - Epoch [14][40/57]	lr: 3.907e-02, eta: 0:03:45, time: 0.178, data_time: 0.128, memory: 861, top1_acc: 0.8406, top5_acc: 0.9922, loss_cls: 0.5524, loss: 0.5524, grad_norm: 1.3769
2023-02-21 16:35:47,967 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:35:47,968 - pyskl - INFO - 
top1_acc	0.9571
top5_acc	1.0000
2023-02-21 16:35:47,968 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:35:47,969 - pyskl - INFO - 
mean_acc	0.9571
2023-02-21 16:35:47,971 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lrd1/best_top1_acc_epoch_11.pth was removed
2023-02-21 16:35:48,001 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_14.pth.
2023-02-21 16:35:48,001 - pyskl - INFO - Best top1_acc is 0.9571 at 14 epoch.
2023-02-21 16:35:48,002 - pyskl - INFO - Epoch(val) [14][5]	top1_acc: 0.9571, top5_acc: 1.0000, mean_class_accuracy: 0.9571
2023-02-21 16:36:05,808 - pyskl - INFO - Epoch [15][20/57]	lr: 3.496e-02, eta: 0:03:33, time: 0.890, data_time: 0.724, memory: 861, top1_acc: 0.8484, top5_acc: 0.9984, loss_cls: 0.4364, loss: 0.4364, grad_norm: 1.2455
2023-02-21 16:36:09,379 - pyskl - INFO - Epoch [15][40/57]	lr: 3.279e-02, eta: 0:03:23, time: 0.178, data_time: 0.000, memory: 861, top1_acc: 0.8703, top5_acc: 0.9953, loss_cls: 0.4147, loss: 0.4147, grad_norm: 1.1932
2023-02-21 16:36:28,897 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:36:28,897 - pyskl - INFO - 
top1_acc	0.9786
top5_acc	1.0000
2023-02-21 16:36:28,897 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:36:28,898 - pyskl - INFO - 
mean_acc	0.9786
2023-02-21 16:36:28,899 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lrd1/best_top1_acc_epoch_14.pth was removed
2023-02-21 16:36:28,925 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_15.pth.
2023-02-21 16:36:28,925 - pyskl - INFO - Best top1_acc is 0.9786 at 15 epoch.
2023-02-21 16:36:28,925 - pyskl - INFO - Epoch(val) [15][5]	top1_acc: 0.9786, top5_acc: 1.0000, mean_class_accuracy: 0.9786
2023-02-21 16:36:46,550 - pyskl - INFO - Epoch [16][20/57]	lr: 2.887e-02, eta: 0:03:10, time: 0.881, data_time: 0.821, memory: 861, top1_acc: 0.8594, top5_acc: 0.9953, loss_cls: 0.4568, loss: 0.4568, grad_norm: 1.2416
2023-02-21 16:36:50,184 - pyskl - INFO - Epoch [16][40/57]	lr: 2.681e-02, eta: 0:03:00, time: 0.182, data_time: 0.105, memory: 861, top1_acc: 0.8781, top5_acc: 0.9938, loss_cls: 0.4373, loss: 0.4373, grad_norm: 1.0549
2023-02-21 16:37:09,998 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:37:09,999 - pyskl - INFO - 
top1_acc	0.9643
top5_acc	1.0000
2023-02-21 16:37:09,999 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:37:09,999 - pyskl - INFO - 
mean_acc	0.9643
2023-02-21 16:37:09,999 - pyskl - INFO - Epoch(val) [16][5]	top1_acc: 0.9643, top5_acc: 1.0000, mean_class_accuracy: 0.9643
2023-02-21 16:37:27,630 - pyskl - INFO - Epoch [17][20/57]	lr: 2.314e-02, eta: 0:02:48, time: 0.881, data_time: 0.827, memory: 861, top1_acc: 0.8562, top5_acc: 1.0000, loss_cls: 0.4718, loss: 0.4718, grad_norm: 1.2310
2023-02-21 16:37:31,281 - pyskl - INFO - Epoch [17][40/57]	lr: 2.123e-02, eta: 0:02:38, time: 0.183, data_time: 0.108, memory: 861, top1_acc: 0.8734, top5_acc: 0.9953, loss_cls: 0.3947, loss: 0.3947, grad_norm: 1.1836
2023-02-21 16:37:51,127 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:37:51,127 - pyskl - INFO - 
top1_acc	0.9571
top5_acc	1.0000
2023-02-21 16:37:51,128 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:37:51,128 - pyskl - INFO - 
mean_acc	0.9571
2023-02-21 16:37:51,128 - pyskl - INFO - Epoch(val) [17][5]	top1_acc: 0.9571, top5_acc: 1.0000, mean_class_accuracy: 0.9571
2023-02-21 16:38:08,846 - pyskl - INFO - Epoch [18][20/57]	lr: 1.786e-02, eta: 0:02:26, time: 0.886, data_time: 0.838, memory: 861, top1_acc: 0.8734, top5_acc: 0.9938, loss_cls: 0.4202, loss: 0.4202, grad_norm: 1.1615
2023-02-21 16:38:12,375 - pyskl - INFO - Epoch [18][40/57]	lr: 1.614e-02, eta: 0:02:16, time: 0.176, data_time: 0.127, memory: 861, top1_acc: 0.8969, top5_acc: 0.9953, loss_cls: 0.3547, loss: 0.3547, grad_norm: 1.0619
2023-02-21 16:38:32,344 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:38:32,345 - pyskl - INFO - 
top1_acc	0.9786
top5_acc	1.0000
2023-02-21 16:38:32,345 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:38:32,345 - pyskl - INFO - 
mean_acc	0.9786
2023-02-21 16:38:32,345 - pyskl - INFO - Epoch(val) [18][5]	top1_acc: 0.9786, top5_acc: 1.0000, mean_class_accuracy: 0.9786
2023-02-21 16:38:50,034 - pyskl - INFO - Epoch [19][20/57]	lr: 1.314e-02, eta: 0:02:03, time: 0.884, data_time: 0.799, memory: 861, top1_acc: 0.8656, top5_acc: 0.9969, loss_cls: 0.4194, loss: 0.4194, grad_norm: 1.1915
2023-02-21 16:38:53,556 - pyskl - INFO - Epoch [19][40/57]	lr: 1.162e-02, eta: 0:01:55, time: 0.176, data_time: 0.077, memory: 861, top1_acc: 0.8906, top5_acc: 0.9984, loss_cls: 0.3606, loss: 0.3606, grad_norm: 1.0691
2023-02-21 16:39:13,354 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:39:13,354 - pyskl - INFO - 
top1_acc	0.9571
top5_acc	1.0000
2023-02-21 16:39:13,355 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:39:13,355 - pyskl - INFO - 
mean_acc	0.9571
2023-02-21 16:39:13,355 - pyskl - INFO - Epoch(val) [19][5]	top1_acc: 0.9571, top5_acc: 1.0000, mean_class_accuracy: 0.9571
2023-02-21 16:39:31,139 - pyskl - INFO - Epoch [20][20/57]	lr: 9.042e-03, eta: 0:01:41, time: 0.889, data_time: 0.839, memory: 861, top1_acc: 0.9047, top5_acc: 0.9969, loss_cls: 0.3149, loss: 0.3149, grad_norm: 0.9861
2023-02-21 16:39:34,780 - pyskl - INFO - Epoch [20][40/57]	lr: 7.769e-03, eta: 0:01:33, time: 0.182, data_time: 0.135, memory: 861, top1_acc: 0.8969, top5_acc: 0.9969, loss_cls: 0.3167, loss: 0.3167, grad_norm: 1.0132
2023-02-21 16:39:54,508 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:39:54,509 - pyskl - INFO - 
top1_acc	0.9786
top5_acc	1.0000
2023-02-21 16:39:54,509 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:39:54,509 - pyskl - INFO - 
mean_acc	0.9786
2023-02-21 16:39:54,509 - pyskl - INFO - Epoch(val) [20][5]	top1_acc: 0.9786, top5_acc: 1.0000, mean_class_accuracy: 0.9786
2023-02-21 16:40:12,429 - pyskl - INFO - Epoch [21][20/57]	lr: 5.649e-03, eta: 0:01:19, time: 0.895, data_time: 0.841, memory: 861, top1_acc: 0.8734, top5_acc: 0.9984, loss_cls: 0.3699, loss: 0.3699, grad_norm: 1.0804
2023-02-21 16:40:15,999 - pyskl - INFO - Epoch [21][40/57]	lr: 4.636e-03, eta: 0:01:11, time: 0.179, data_time: 0.126, memory: 861, top1_acc: 0.8891, top5_acc: 0.9984, loss_cls: 0.3451, loss: 0.3451, grad_norm: 1.0829
2023-02-21 16:40:36,228 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:40:36,229 - pyskl - INFO - 
top1_acc	0.9857
top5_acc	1.0000
2023-02-21 16:40:36,229 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:40:36,230 - pyskl - INFO - 
mean_acc	0.9857
2023-02-21 16:40:36,232 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp0/t7nsnr_5p_lrd1/best_top1_acc_epoch_15.pth was removed
2023-02-21 16:40:36,261 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_21.pth.
2023-02-21 16:40:36,261 - pyskl - INFO - Best top1_acc is 0.9857 at 21 epoch.
2023-02-21 16:40:36,261 - pyskl - INFO - Epoch(val) [21][5]	top1_acc: 0.9857, top5_acc: 1.0000, mean_class_accuracy: 0.9857
2023-02-21 16:40:54,277 - pyskl - INFO - Epoch [22][20/57]	lr: 3.015e-03, eta: 0:00:57, time: 0.901, data_time: 0.840, memory: 861, top1_acc: 0.8969, top5_acc: 0.9969, loss_cls: 0.3305, loss: 0.3305, grad_norm: 1.0170
2023-02-21 16:40:57,942 - pyskl - INFO - Epoch [22][40/57]	lr: 2.280e-03, eta: 0:00:49, time: 0.183, data_time: 0.113, memory: 861, top1_acc: 0.8875, top5_acc: 0.9969, loss_cls: 0.3151, loss: 0.3151, grad_norm: 1.1194
2023-02-21 16:41:17,714 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:41:17,715 - pyskl - INFO - 
top1_acc	0.9857
top5_acc	1.0000
2023-02-21 16:41:17,715 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:41:17,715 - pyskl - INFO - 
mean_acc	0.9857
2023-02-21 16:41:17,716 - pyskl - INFO - Epoch(val) [22][5]	top1_acc: 0.9857, top5_acc: 1.0000, mean_class_accuracy: 0.9857
2023-02-21 16:41:35,543 - pyskl - INFO - Epoch [23][20/57]	lr: 1.185e-03, eta: 0:00:36, time: 0.891, data_time: 0.711, memory: 861, top1_acc: 0.8703, top5_acc: 0.9969, loss_cls: 0.3889, loss: 0.3889, grad_norm: 1.1162
2023-02-21 16:41:39,323 - pyskl - INFO - Epoch [23][40/57]	lr: 7.398e-04, eta: 0:00:28, time: 0.189, data_time: 0.002, memory: 861, top1_acc: 0.8734, top5_acc: 0.9984, loss_cls: 0.3603, loss: 0.3603, grad_norm: 1.0877
2023-02-21 16:41:59,185 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:41:59,186 - pyskl - INFO - 
top1_acc	0.9786
top5_acc	1.0000
2023-02-21 16:41:59,186 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:41:59,186 - pyskl - INFO - 
mean_acc	0.9786
2023-02-21 16:41:59,187 - pyskl - INFO - Epoch(val) [23][5]	top1_acc: 0.9786, top5_acc: 1.0000, mean_class_accuracy: 0.9786
2023-02-21 16:42:17,161 - pyskl - INFO - Epoch [24][20/57]	lr: 1.903e-04, eta: 0:00:14, time: 0.898, data_time: 0.765, memory: 861, top1_acc: 0.8984, top5_acc: 1.0000, loss_cls: 0.3139, loss: 0.3139, grad_norm: 1.0723
2023-02-21 16:42:20,704 - pyskl - INFO - Epoch [24][40/57]	lr: 4.271e-05, eta: 0:00:06, time: 0.177, data_time: 0.058, memory: 861, top1_acc: 0.8953, top5_acc: 0.9984, loss_cls: 0.3208, loss: 0.3208, grad_norm: 1.0098
2023-02-21 16:42:24,234 - pyskl - INFO - Saving checkpoint at 24 epochs
2023-02-21 16:42:40,443 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-21 16:42:40,444 - pyskl - INFO - 
top1_acc	0.9786
top5_acc	1.0000
2023-02-21 16:42:40,444 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-21 16:42:40,445 - pyskl - INFO - 
mean_acc	0.9786
2023-02-21 16:42:40,445 - pyskl - INFO - Epoch(val) [24][5]	top1_acc: 0.9786, top5_acc: 1.0000, mean_class_accuracy: 0.9786
