2023-02-23 11:40:08,562 - pyskl - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Jan 17 2023, 23:13:24) [GCC 11.2.0]
CUDA available: True
GPU 0,1,2,3: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.6, V11.6.55
GCC: gcc (Ubuntu 7.5.0-6ubuntu2) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.7.0
MMCV: 1.6.2
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
pyskl: 0.1.0+HEAD
------------------------------------------------------------

2023-02-23 11:40:09,798 - pyskl - INFO - Config: model = dict(
    type='Recognizer3D',
    backbone=dict(
        type='ResNet3dSlowOnly',
        in_channels=5,
        base_channels=32,
        num_stages=3,
        out_indices=(2, ),
        stage_blocks=(4, 6, 3),
        conv1_stride=(1, 1),
        pool1_stride=(1, 1),
        inflate=(0, 1, 1),
        spatial_strides=(2, 2, 2),
        temporal_strides=(1, 1, 2),
        frozen_stages=3),
    cls_head=dict(
        type='I3DHead', in_channels=512, num_classes=10, dropout=0.5),
    test_cfg=dict(average_clips='prob'))
dataset_type = 'PoseDataset'
ann_file = 'data/ds_taichi/test5nsnr.pkl'
left_kp = [
    5, 6, 7, 8, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,
    60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71
]
right_kp = [
    1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
    32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43
]
train_pipeline = [
    dict(type='UniformSampleFrames', clip_len=48),
    dict(type='PoseDecode'),
    dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
    dict(type='Resize', scale=(-1, 64)),
    dict(type='RandomResizedCrop', area_range=(0.56, 1.0)),
    dict(type='Resize', scale=(56, 56), keep_ratio=False),
    dict(
        type='Flip',
        flip_ratio=0.5,
        left_kp=[
            5, 6, 7, 8, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,
            58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71
        ],
        right_kp=[
            1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,
            30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43
        ]),
    dict(type='GenerateTaiChiPoseTarget', with_kp=True, with_limb=False),
    dict(type='FormatShape', input_format='NCTHW_Heatmap'),
    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
    dict(type='ToTensor', keys=['imgs', 'label'])
]
val_pipeline = [
    dict(type='UniformSampleFrames', clip_len=48, num_clips=1),
    dict(type='PoseDecode'),
    dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
    dict(type='Resize', scale=(64, 64), keep_ratio=False),
    dict(type='GenerateTaiChiPoseTarget', with_kp=True, with_limb=False),
    dict(type='FormatShape', input_format='NCTHW_Heatmap'),
    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
    dict(type='ToTensor', keys=['imgs'])
]
test_pipeline = [
    dict(type='UniformSampleFrames', clip_len=48, num_clips=10),
    dict(type='PoseDecode'),
    dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
    dict(type='Resize', scale=(64, 64), keep_ratio=False),
    dict(
        type='GenerateTaiChiPoseTarget',
        with_kp=True,
        with_limb=False,
        double=True),
    dict(type='FormatShape', input_format='NCTHW_Heatmap'),
    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
    dict(type='ToTensor', keys=['imgs'])
]
data = dict(
    videos_per_gpu=8,
    workers_per_gpu=4,
    test_dataloader=dict(videos_per_gpu=6),
    train=dict(
        type='RepeatDataset',
        times=30,
        dataset=dict(
            type='PoseDataset',
            ann_file='data/ds_taichi/test5nsnr.pkl',
            split='train',
            pipeline=[
                dict(type='UniformSampleFrames', clip_len=48),
                dict(type='PoseDecode'),
                dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
                dict(type='Resize', scale=(-1, 64)),
                dict(type='RandomResizedCrop', area_range=(0.56, 1.0)),
                dict(type='Resize', scale=(56, 56), keep_ratio=False),
                dict(
                    type='Flip',
                    flip_ratio=0.5,
                    left_kp=[
                        5, 6, 7, 8, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,
                        55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,
                        69, 70, 71
                    ],
                    right_kp=[
                        1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,
                        27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,
                        41, 42, 43
                    ]),
                dict(
                    type='GenerateTaiChiPoseTarget',
                    with_kp=True,
                    with_limb=False),
                dict(type='FormatShape', input_format='NCTHW_Heatmap'),
                dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
                dict(type='ToTensor', keys=['imgs', 'label'])
            ])),
    val=dict(
        type='PoseDataset',
        ann_file='data/ds_taichi/test5nsnr.pkl',
        split='test',
        pipeline=[
            dict(type='UniformSampleFrames', clip_len=48, num_clips=1),
            dict(type='PoseDecode'),
            dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
            dict(type='Resize', scale=(64, 64), keep_ratio=False),
            dict(
                type='GenerateTaiChiPoseTarget', with_kp=True,
                with_limb=False),
            dict(type='FormatShape', input_format='NCTHW_Heatmap'),
            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
            dict(type='ToTensor', keys=['imgs'])
        ]),
    test=dict(
        type='PoseDataset',
        ann_file='data/ds_taichi/test5nsnr.pkl',
        split='test',
        pipeline=[
            dict(type='UniformSampleFrames', clip_len=48, num_clips=10),
            dict(type='PoseDecode'),
            dict(type='PoseCompact', hw_ratio=1.0, allow_imgpad=True),
            dict(type='Resize', scale=(64, 64), keep_ratio=False),
            dict(
                type='GenerateTaiChiPoseTarget',
                with_kp=True,
                with_limb=False,
                double=True),
            dict(type='FormatShape', input_format='NCTHW_Heatmap'),
            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),
            dict(type='ToTensor', keys=['imgs'])
        ]))
optimizer = dict(type='SGD', lr=0.4, momentum=0.9, weight_decay=0.0003)
optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))
lr_config = dict(policy='CosineAnnealing', by_epoch=False, min_lr=0)
total_epochs = 24
checkpoint_config = dict(interval=24)
evaluation = dict(
    interval=1, metrics=['top_k_accuracy', 'mean_class_accuracy'], topk=(1, 5))
log_config = dict(interval=20, hooks=[dict(type='TextLoggerHook')])
log_level = 'INFO'
output_config = dict(
    out='./model_pth/exp4/t5nsnr_wfwc/test_result/results.pkl')
eval_config = dict(
    metric_out='./model_pth/exp4/t5nsnr_wfwc/test_result',
    eval=[
        'top_k_accuracy', 'mean_class_accuracy', 'confusion_matrix',
        't_sne_vis'
    ])
work_dir = './model_pth/exp4/t5nsnr_wfwc'
load_from = './model_pth/ntu120xsub_5parts_kp/best_top1_acc_epoch_23.pth'
find_unused_parameters = True
dist_params = dict(backend='nccl')
gpu_ids = range(0, 4)

2023-02-23 11:40:09,799 - pyskl - INFO - Set random seed to 42, deterministic: True
2023-02-23 11:40:10,442 - pyskl - INFO - 100 videos remain after valid thresholding
2023-02-23 11:40:15,830 - pyskl - INFO - 100 videos remain after valid thresholding
2023-02-23 11:40:15,832 - pyskl - INFO - load checkpoint from local path: ./model_pth/ntu120xsub_5parts_kp/best_top1_acc_epoch_23.pth
2023-02-23 11:40:15,854 - pyskl - WARNING - The model and loaded state dict do not match exactly

size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([120, 512]) from checkpoint, the shape in current model is torch.Size([10, 512]).
size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([120]) from checkpoint, the shape in current model is torch.Size([10]).
2023-02-23 11:40:15,854 - pyskl - INFO - Start running, host: yl@83090-jin, work_dir: /home/yl/sscls/model_pth/exp4/t5nsnr_wfwc
2023-02-23 11:40:15,855 - pyskl - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(NORMAL      ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) DistEvalHook                       
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) DistEvalHook                       
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) DistEvalHook                       
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-02-23 11:40:15,855 - pyskl - INFO - workflow: [('train', 1)], max: 24 epochs
2023-02-23 11:40:15,855 - pyskl - INFO - Checkpoints will be saved to /home/yl/sscls/model_pth/exp4/t5nsnr_wfwc by HardDiskBackend.
2023-02-23 11:40:34,224 - pyskl - INFO - Epoch [1][20/94]	lr: 3.999e-01, eta: 0:34:13, time: 0.918, data_time: 0.791, memory: 664, top1_acc: 0.1891, top5_acc: 0.5781, loss_cls: 18.5190, loss: 18.5190, grad_norm: 6.6581
2023-02-23 11:40:37,854 - pyskl - INFO - Epoch [1][40/94]	lr: 3.997e-01, eta: 0:20:18, time: 0.181, data_time: 0.058, memory: 664, top1_acc: 0.3469, top5_acc: 0.7844, loss_cls: 16.5474, loss: 16.5474, grad_norm: 4.7419
2023-02-23 11:40:41,476 - pyskl - INFO - Epoch [1][60/94]	lr: 3.993e-01, eta: 0:15:37, time: 0.181, data_time: 0.033, memory: 664, top1_acc: 0.4891, top5_acc: 0.8969, loss_cls: 9.2501, loss: 9.2501, grad_norm: 3.5535
2023-02-23 11:40:45,109 - pyskl - INFO - Epoch [1][80/94]	lr: 3.988e-01, eta: 0:13:15, time: 0.181, data_time: 0.041, memory: 664, top1_acc: 0.5297, top5_acc: 0.9062, loss_cls: 9.2543, loss: 9.2543, grad_norm: 3.4315
2023-02-23 11:41:03,974 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:41:03,975 - pyskl - INFO - 
top1_acc	0.6000
top5_acc	0.8900
2023-02-23 11:41:03,975 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:41:03,975 - pyskl - INFO - 
mean_acc	0.6000
2023-02-23 11:41:04,002 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_1.pth.
2023-02-23 11:41:04,002 - pyskl - INFO - Best top1_acc is 0.6000 at 1 epoch.
2023-02-23 11:41:04,002 - pyskl - INFO - Epoch(val) [1][4]	top1_acc: 0.6000, top5_acc: 0.8900, mean_class_accuracy: 0.6000
2023-02-23 11:41:21,987 - pyskl - INFO - Epoch [2][20/94]	lr: 3.975e-01, eta: 0:14:47, time: 0.899, data_time: 0.834, memory: 861, top1_acc: 0.5656, top5_acc: 0.9437, loss_cls: 7.8252, loss: 7.8252, grad_norm: 3.0537
2023-02-23 11:41:25,599 - pyskl - INFO - Epoch [2][40/94]	lr: 3.966e-01, eta: 0:13:25, time: 0.181, data_time: 0.090, memory: 861, top1_acc: 0.5844, top5_acc: 0.9609, loss_cls: 7.2592, loss: 7.2592, grad_norm: 2.9446
2023-02-23 11:41:29,178 - pyskl - INFO - Epoch [2][60/94]	lr: 3.955e-01, eta: 0:12:22, time: 0.179, data_time: 0.081, memory: 861, top1_acc: 0.5656, top5_acc: 0.9484, loss_cls: 8.0819, loss: 8.0819, grad_norm: 3.3289
2023-02-23 11:41:32,735 - pyskl - INFO - Epoch [2][80/94]	lr: 3.942e-01, eta: 0:11:33, time: 0.178, data_time: 0.056, memory: 861, top1_acc: 0.5969, top5_acc: 0.9609, loss_cls: 7.3792, loss: 7.3792, grad_norm: 3.0571
2023-02-23 11:41:51,777 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:41:51,778 - pyskl - INFO - 
top1_acc	0.7400
top5_acc	1.0000
2023-02-23 11:41:51,778 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:41:51,778 - pyskl - INFO - 
mean_acc	0.7400
2023-02-23 11:41:51,779 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp4/t5nsnr_wfwc/best_top1_acc_epoch_1.pth was removed
2023-02-23 11:41:51,805 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_2.pth.
2023-02-23 11:41:51,805 - pyskl - INFO - Best top1_acc is 0.7400 at 2 epoch.
2023-02-23 11:41:51,805 - pyskl - INFO - Epoch(val) [2][4]	top1_acc: 0.7400, top5_acc: 1.0000, mean_class_accuracy: 0.7400
2023-02-23 11:42:09,659 - pyskl - INFO - Epoch [3][20/94]	lr: 3.917e-01, eta: 0:12:26, time: 0.893, data_time: 0.753, memory: 861, top1_acc: 0.6141, top5_acc: 0.9516, loss_cls: 8.1952, loss: 8.1952, grad_norm: 2.8590
2023-02-23 11:42:13,438 - pyskl - INFO - Epoch [3][40/94]	lr: 3.901e-01, eta: 0:11:48, time: 0.189, data_time: 0.004, memory: 861, top1_acc: 0.6125, top5_acc: 0.9641, loss_cls: 6.8726, loss: 6.8726, grad_norm: 2.9362
2023-02-23 11:42:17,125 - pyskl - INFO - Epoch [3][60/94]	lr: 3.883e-01, eta: 0:11:14, time: 0.184, data_time: 0.000, memory: 861, top1_acc: 0.6266, top5_acc: 0.9703, loss_cls: 6.4300, loss: 6.4300, grad_norm: 2.8126
2023-02-23 11:42:20,711 - pyskl - INFO - Epoch [3][80/94]	lr: 3.863e-01, eta: 0:10:44, time: 0.179, data_time: 0.000, memory: 861, top1_acc: 0.6891, top5_acc: 0.9641, loss_cls: 5.5032, loss: 5.5032, grad_norm: 2.3763
2023-02-23 11:42:40,349 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:42:40,350 - pyskl - INFO - 
top1_acc	0.8100
top5_acc	0.9200
2023-02-23 11:42:40,350 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:42:40,350 - pyskl - INFO - 
mean_acc	0.8100
2023-02-23 11:42:40,352 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp4/t5nsnr_wfwc/best_top1_acc_epoch_2.pth was removed
2023-02-23 11:42:40,377 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_3.pth.
2023-02-23 11:42:40,377 - pyskl - INFO - Best top1_acc is 0.8100 at 3 epoch.
2023-02-23 11:42:40,377 - pyskl - INFO - Epoch(val) [3][4]	top1_acc: 0.8100, top5_acc: 0.9200, mean_class_accuracy: 0.8100
2023-02-23 11:42:58,270 - pyskl - INFO - Epoch [4][20/94]	lr: 3.827e-01, eta: 0:11:17, time: 0.894, data_time: 0.847, memory: 861, top1_acc: 0.6516, top5_acc: 0.9531, loss_cls: 6.8546, loss: 6.8546, grad_norm: 2.7421
2023-02-23 11:43:01,780 - pyskl - INFO - Epoch [4][40/94]	lr: 3.803e-01, eta: 0:10:50, time: 0.175, data_time: 0.128, memory: 861, top1_acc: 0.7063, top5_acc: 0.9797, loss_cls: 5.1585, loss: 5.1585, grad_norm: 2.4471
2023-02-23 11:43:05,355 - pyskl - INFO - Epoch [4][60/94]	lr: 3.779e-01, eta: 0:10:25, time: 0.179, data_time: 0.129, memory: 861, top1_acc: 0.7016, top5_acc: 0.9719, loss_cls: 4.2729, loss: 4.2729, grad_norm: 2.3392
2023-02-23 11:43:08,891 - pyskl - INFO - Epoch [4][80/94]	lr: 3.753e-01, eta: 0:10:03, time: 0.177, data_time: 0.113, memory: 861, top1_acc: 0.7000, top5_acc: 0.9828, loss_cls: 4.5466, loss: 4.5466, grad_norm: 2.3192
2023-02-23 11:43:28,207 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:43:28,207 - pyskl - INFO - 
top1_acc	0.9000
top5_acc	1.0000
2023-02-23 11:43:28,207 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:43:28,208 - pyskl - INFO - 
mean_acc	0.9000
2023-02-23 11:43:28,209 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp4/t5nsnr_wfwc/best_top1_acc_epoch_3.pth was removed
2023-02-23 11:43:28,235 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_4.pth.
2023-02-23 11:43:28,235 - pyskl - INFO - Best top1_acc is 0.9000 at 4 epoch.
2023-02-23 11:43:28,235 - pyskl - INFO - Epoch(val) [4][4]	top1_acc: 0.9000, top5_acc: 1.0000, mean_class_accuracy: 0.9000
2023-02-23 11:43:46,181 - pyskl - INFO - Epoch [5][20/94]	lr: 3.705e-01, eta: 0:10:26, time: 0.897, data_time: 0.786, memory: 861, top1_acc: 0.7203, top5_acc: 0.9812, loss_cls: 4.4563, loss: 4.4563, grad_norm: 2.2326
2023-02-23 11:43:49,890 - pyskl - INFO - Epoch [5][40/94]	lr: 3.675e-01, eta: 0:10:06, time: 0.185, data_time: 0.022, memory: 861, top1_acc: 0.7375, top5_acc: 0.9812, loss_cls: 3.6552, loss: 3.6552, grad_norm: 1.9748
2023-02-23 11:43:53,412 - pyskl - INFO - Epoch [5][60/94]	lr: 3.644e-01, eta: 0:09:46, time: 0.176, data_time: 0.007, memory: 861, top1_acc: 0.7172, top5_acc: 0.9812, loss_cls: 4.0212, loss: 4.0212, grad_norm: 2.2055
2023-02-23 11:43:57,070 - pyskl - INFO - Epoch [5][80/94]	lr: 3.612e-01, eta: 0:09:29, time: 0.183, data_time: 0.007, memory: 861, top1_acc: 0.6984, top5_acc: 0.9812, loss_cls: 4.7344, loss: 4.7344, grad_norm: 2.3966
2023-02-23 11:44:16,601 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:44:16,602 - pyskl - INFO - 
top1_acc	0.8700
top5_acc	0.9900
2023-02-23 11:44:16,602 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:44:16,602 - pyskl - INFO - 
mean_acc	0.8700
2023-02-23 11:44:16,602 - pyskl - INFO - Epoch(val) [5][4]	top1_acc: 0.8700, top5_acc: 0.9900, mean_class_accuracy: 0.8700
2023-02-23 11:44:34,372 - pyskl - INFO - Epoch [6][20/94]	lr: 3.554e-01, eta: 0:09:43, time: 0.888, data_time: 0.830, memory: 861, top1_acc: 0.7063, top5_acc: 0.9812, loss_cls: 3.9210, loss: 3.9210, grad_norm: 2.3023
2023-02-23 11:44:38,075 - pyskl - INFO - Epoch [6][40/94]	lr: 3.518e-01, eta: 0:09:27, time: 0.185, data_time: 0.137, memory: 861, top1_acc: 0.7672, top5_acc: 0.9812, loss_cls: 3.4627, loss: 3.4627, grad_norm: 1.9660
2023-02-23 11:44:41,912 - pyskl - INFO - Epoch [6][60/94]	lr: 3.481e-01, eta: 0:09:12, time: 0.192, data_time: 0.140, memory: 861, top1_acc: 0.7203, top5_acc: 0.9828, loss_cls: 3.5370, loss: 3.5370, grad_norm: 2.2999
2023-02-23 11:44:45,624 - pyskl - INFO - Epoch [6][80/94]	lr: 3.443e-01, eta: 0:08:57, time: 0.185, data_time: 0.124, memory: 861, top1_acc: 0.7203, top5_acc: 0.9750, loss_cls: 3.9013, loss: 3.9013, grad_norm: 2.1356
2023-02-23 11:45:04,640 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:45:04,641 - pyskl - INFO - 
top1_acc	0.9800
top5_acc	1.0000
2023-02-23 11:45:04,641 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:45:04,641 - pyskl - INFO - 
mean_acc	0.9800
2023-02-23 11:45:04,643 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp4/t5nsnr_wfwc/best_top1_acc_epoch_4.pth was removed
2023-02-23 11:45:04,674 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_6.pth.
2023-02-23 11:45:04,674 - pyskl - INFO - Best top1_acc is 0.9800 at 6 epoch.
2023-02-23 11:45:04,674 - pyskl - INFO - Epoch(val) [6][4]	top1_acc: 0.9800, top5_acc: 1.0000, mean_class_accuracy: 0.9800
2023-02-23 11:45:22,337 - pyskl - INFO - Epoch [7][20/94]	lr: 3.376e-01, eta: 0:09:06, time: 0.883, data_time: 0.795, memory: 861, top1_acc: 0.7438, top5_acc: 0.9859, loss_cls: 2.8677, loss: 2.8677, grad_norm: 1.9657
2023-02-23 11:45:25,861 - pyskl - INFO - Epoch [7][40/94]	lr: 3.335e-01, eta: 0:08:51, time: 0.176, data_time: 0.072, memory: 861, top1_acc: 0.7312, top5_acc: 0.9781, loss_cls: 3.6324, loss: 3.6324, grad_norm: 2.2462
2023-02-23 11:45:29,415 - pyskl - INFO - Epoch [7][60/94]	lr: 3.293e-01, eta: 0:08:37, time: 0.178, data_time: 0.054, memory: 861, top1_acc: 0.7031, top5_acc: 0.9797, loss_cls: 4.4989, loss: 4.4989, grad_norm: 2.4279
2023-02-23 11:45:32,957 - pyskl - INFO - Epoch [7][80/94]	lr: 3.250e-01, eta: 0:08:24, time: 0.177, data_time: 0.037, memory: 861, top1_acc: 0.7422, top5_acc: 0.9828, loss_cls: 3.8076, loss: 3.8076, grad_norm: 2.2997
2023-02-23 11:45:52,112 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:45:52,113 - pyskl - INFO - 
top1_acc	0.9300
top5_acc	1.0000
2023-02-23 11:45:52,113 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:45:52,113 - pyskl - INFO - 
mean_acc	0.9300
2023-02-23 11:45:52,113 - pyskl - INFO - Epoch(val) [7][4]	top1_acc: 0.9300, top5_acc: 1.0000, mean_class_accuracy: 0.9300
2023-02-23 11:46:10,484 - pyskl - INFO - Epoch [8][20/94]	lr: 3.175e-01, eta: 0:08:31, time: 0.918, data_time: 0.743, memory: 861, top1_acc: 0.7328, top5_acc: 0.9797, loss_cls: 3.9001, loss: 3.9001, grad_norm: 2.2139
2023-02-23 11:46:14,039 - pyskl - INFO - Epoch [8][40/94]	lr: 3.130e-01, eta: 0:08:18, time: 0.178, data_time: 0.024, memory: 861, top1_acc: 0.7312, top5_acc: 0.9875, loss_cls: 3.4074, loss: 3.4074, grad_norm: 2.2058
2023-02-23 11:46:17,630 - pyskl - INFO - Epoch [8][60/94]	lr: 3.083e-01, eta: 0:08:06, time: 0.180, data_time: 0.034, memory: 861, top1_acc: 0.7297, top5_acc: 0.9844, loss_cls: 3.7052, loss: 3.7052, grad_norm: 2.1932
2023-02-23 11:46:21,235 - pyskl - INFO - Epoch [8][80/94]	lr: 3.036e-01, eta: 0:07:54, time: 0.180, data_time: 0.029, memory: 861, top1_acc: 0.7250, top5_acc: 0.9781, loss_cls: 4.2774, loss: 4.2774, grad_norm: 2.3964
2023-02-23 11:46:40,939 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:46:40,939 - pyskl - INFO - 
top1_acc	0.9200
top5_acc	1.0000
2023-02-23 11:46:40,940 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:46:40,940 - pyskl - INFO - 
mean_acc	0.9200
2023-02-23 11:46:40,940 - pyskl - INFO - Epoch(val) [8][4]	top1_acc: 0.9200, top5_acc: 1.0000, mean_class_accuracy: 0.9200
2023-02-23 11:46:59,095 - pyskl - INFO - Epoch [9][20/94]	lr: 2.954e-01, eta: 0:07:58, time: 0.908, data_time: 0.732, memory: 861, top1_acc: 0.7656, top5_acc: 0.9844, loss_cls: 2.8356, loss: 2.8356, grad_norm: 1.9464
2023-02-23 11:47:02,594 - pyskl - INFO - Epoch [9][40/94]	lr: 2.905e-01, eta: 0:07:46, time: 0.175, data_time: 0.000, memory: 861, top1_acc: 0.7859, top5_acc: 0.9938, loss_cls: 2.5816, loss: 2.5816, grad_norm: 1.7992
2023-02-23 11:47:06,251 - pyskl - INFO - Epoch [9][60/94]	lr: 2.854e-01, eta: 0:07:35, time: 0.183, data_time: 0.001, memory: 861, top1_acc: 0.7906, top5_acc: 0.9891, loss_cls: 2.2085, loss: 2.2085, grad_norm: 1.7080
2023-02-23 11:47:09,769 - pyskl - INFO - Epoch [9][80/94]	lr: 2.804e-01, eta: 0:07:24, time: 0.176, data_time: 0.001, memory: 861, top1_acc: 0.7391, top5_acc: 0.9906, loss_cls: 2.9186, loss: 2.9186, grad_norm: 2.0165
2023-02-23 11:47:28,957 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:47:28,958 - pyskl - INFO - 
top1_acc	0.8800
top5_acc	1.0000
2023-02-23 11:47:28,958 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:47:28,959 - pyskl - INFO - 
mean_acc	0.8800
2023-02-23 11:47:28,959 - pyskl - INFO - Epoch(val) [9][4]	top1_acc: 0.8800, top5_acc: 1.0000, mean_class_accuracy: 0.8800
2023-02-23 11:47:46,898 - pyskl - INFO - Epoch [10][20/94]	lr: 2.716e-01, eta: 0:07:25, time: 0.897, data_time: 0.818, memory: 861, top1_acc: 0.7422, top5_acc: 0.9859, loss_cls: 3.1951, loss: 3.1951, grad_norm: 2.1620
2023-02-23 11:47:50,454 - pyskl - INFO - Epoch [10][40/94]	lr: 2.664e-01, eta: 0:07:14, time: 0.178, data_time: 0.101, memory: 861, top1_acc: 0.7328, top5_acc: 0.9922, loss_cls: 2.9675, loss: 2.9675, grad_norm: 2.1031
2023-02-23 11:47:53,995 - pyskl - INFO - Epoch [10][60/94]	lr: 2.611e-01, eta: 0:07:03, time: 0.177, data_time: 0.107, memory: 861, top1_acc: 0.7359, top5_acc: 0.9906, loss_cls: 3.0922, loss: 3.0922, grad_norm: 2.2095
2023-02-23 11:47:57,595 - pyskl - INFO - Epoch [10][80/94]	lr: 2.558e-01, eta: 0:06:53, time: 0.180, data_time: 0.110, memory: 861, top1_acc: 0.7734, top5_acc: 0.9891, loss_cls: 2.6087, loss: 2.6087, grad_norm: 1.8077
2023-02-23 11:48:16,500 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:48:16,501 - pyskl - INFO - 
top1_acc	0.9800
top5_acc	1.0000
2023-02-23 11:48:16,501 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:48:16,501 - pyskl - INFO - 
mean_acc	0.9800
2023-02-23 11:48:16,502 - pyskl - INFO - Epoch(val) [10][4]	top1_acc: 0.9800, top5_acc: 1.0000, mean_class_accuracy: 0.9800
2023-02-23 11:48:34,466 - pyskl - INFO - Epoch [11][20/94]	lr: 2.466e-01, eta: 0:06:53, time: 0.898, data_time: 0.780, memory: 861, top1_acc: 0.7844, top5_acc: 0.9938, loss_cls: 1.9925, loss: 1.9925, grad_norm: 1.8647
2023-02-23 11:48:38,065 - pyskl - INFO - Epoch [11][40/94]	lr: 2.412e-01, eta: 0:06:43, time: 0.180, data_time: 0.062, memory: 861, top1_acc: 0.7656, top5_acc: 0.9922, loss_cls: 2.1617, loss: 2.1617, grad_norm: 1.9903
2023-02-23 11:48:41,698 - pyskl - INFO - Epoch [11][60/94]	lr: 2.357e-01, eta: 0:06:33, time: 0.182, data_time: 0.064, memory: 861, top1_acc: 0.7734, top5_acc: 0.9938, loss_cls: 2.0683, loss: 2.0683, grad_norm: 1.7641
2023-02-23 11:48:45,306 - pyskl - INFO - Epoch [11][80/94]	lr: 2.302e-01, eta: 0:06:23, time: 0.180, data_time: 0.039, memory: 861, top1_acc: 0.7312, top5_acc: 0.9828, loss_cls: 3.0828, loss: 3.0828, grad_norm: 2.2504
2023-02-23 11:49:04,492 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:49:04,493 - pyskl - INFO - 
top1_acc	0.8600
top5_acc	0.9300
2023-02-23 11:49:04,493 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:49:04,493 - pyskl - INFO - 
mean_acc	0.8600
2023-02-23 11:49:04,493 - pyskl - INFO - Epoch(val) [11][4]	top1_acc: 0.8600, top5_acc: 0.9300, mean_class_accuracy: 0.8600
2023-02-23 11:49:22,515 - pyskl - INFO - Epoch [12][20/94]	lr: 2.209e-01, eta: 0:06:21, time: 0.901, data_time: 0.794, memory: 861, top1_acc: 0.7562, top5_acc: 0.9891, loss_cls: 2.4715, loss: 2.4715, grad_norm: 1.9714
2023-02-23 11:49:26,049 - pyskl - INFO - Epoch [12][40/94]	lr: 2.153e-01, eta: 0:06:12, time: 0.177, data_time: 0.027, memory: 861, top1_acc: 0.8078, top5_acc: 0.9969, loss_cls: 1.7675, loss: 1.7675, grad_norm: 1.5662
2023-02-23 11:49:29,574 - pyskl - INFO - Epoch [12][60/94]	lr: 2.097e-01, eta: 0:06:03, time: 0.176, data_time: 0.013, memory: 861, top1_acc: 0.7875, top5_acc: 0.9922, loss_cls: 2.1912, loss: 2.1912, grad_norm: 1.9477
2023-02-23 11:49:33,166 - pyskl - INFO - Epoch [12][80/94]	lr: 2.042e-01, eta: 0:05:54, time: 0.180, data_time: 0.003, memory: 861, top1_acc: 0.7812, top5_acc: 0.9875, loss_cls: 2.1141, loss: 2.1141, grad_norm: 1.8814
2023-02-23 11:49:52,441 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:49:52,441 - pyskl - INFO - 
top1_acc	0.9100
top5_acc	1.0000
2023-02-23 11:49:52,441 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:49:52,442 - pyskl - INFO - 
mean_acc	0.9100
2023-02-23 11:49:52,442 - pyskl - INFO - Epoch(val) [12][4]	top1_acc: 0.9100, top5_acc: 1.0000, mean_class_accuracy: 0.9100
2023-02-23 11:50:10,796 - pyskl - INFO - Epoch [13][20/94]	lr: 1.947e-01, eta: 0:05:51, time: 0.917, data_time: 0.766, memory: 861, top1_acc: 0.7578, top5_acc: 0.9891, loss_cls: 2.1759, loss: 2.1759, grad_norm: 1.9839
2023-02-23 11:50:14,409 - pyskl - INFO - Epoch [13][40/94]	lr: 1.891e-01, eta: 0:05:42, time: 0.181, data_time: 0.017, memory: 861, top1_acc: 0.7594, top5_acc: 0.9891, loss_cls: 2.4200, loss: 2.4200, grad_norm: 2.0875
2023-02-23 11:50:18,003 - pyskl - INFO - Epoch [13][60/94]	lr: 1.836e-01, eta: 0:05:33, time: 0.180, data_time: 0.005, memory: 861, top1_acc: 0.8078, top5_acc: 0.9953, loss_cls: 1.7365, loss: 1.7365, grad_norm: 1.7192
2023-02-23 11:50:21,554 - pyskl - INFO - Epoch [13][80/94]	lr: 1.780e-01, eta: 0:05:25, time: 0.178, data_time: 0.004, memory: 861, top1_acc: 0.8234, top5_acc: 1.0000, loss_cls: 1.5269, loss: 1.5269, grad_norm: 1.4781
2023-02-23 11:50:40,415 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:50:40,415 - pyskl - INFO - 
top1_acc	0.9800
top5_acc	1.0000
2023-02-23 11:50:40,415 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:50:40,416 - pyskl - INFO - 
mean_acc	0.9800
2023-02-23 11:50:40,416 - pyskl - INFO - Epoch(val) [13][4]	top1_acc: 0.9800, top5_acc: 1.0000, mean_class_accuracy: 0.9800
2023-02-23 11:50:58,248 - pyskl - INFO - Epoch [14][20/94]	lr: 1.687e-01, eta: 0:05:20, time: 0.891, data_time: 0.812, memory: 861, top1_acc: 0.8266, top5_acc: 0.9969, loss_cls: 1.2968, loss: 1.2968, grad_norm: 1.5518
2023-02-23 11:51:01,810 - pyskl - INFO - Epoch [14][40/94]	lr: 1.632e-01, eta: 0:05:11, time: 0.178, data_time: 0.090, memory: 861, top1_acc: 0.8047, top5_acc: 0.9953, loss_cls: 1.5646, loss: 1.5646, grad_norm: 1.6582
2023-02-23 11:51:05,350 - pyskl - INFO - Epoch [14][60/94]	lr: 1.577e-01, eta: 0:05:03, time: 0.177, data_time: 0.074, memory: 861, top1_acc: 0.8125, top5_acc: 0.9891, loss_cls: 1.5778, loss: 1.5778, grad_norm: 1.6359
2023-02-23 11:51:09,034 - pyskl - INFO - Epoch [14][80/94]	lr: 1.523e-01, eta: 0:04:55, time: 0.184, data_time: 0.074, memory: 861, top1_acc: 0.8297, top5_acc: 0.9938, loss_cls: 1.5405, loss: 1.5405, grad_norm: 1.5235
2023-02-23 11:51:28,405 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:51:28,405 - pyskl - INFO - 
top1_acc	0.9800
top5_acc	1.0000
2023-02-23 11:51:28,405 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:51:28,406 - pyskl - INFO - 
mean_acc	0.9800
2023-02-23 11:51:28,406 - pyskl - INFO - Epoch(val) [14][4]	top1_acc: 0.9800, top5_acc: 1.0000, mean_class_accuracy: 0.9800
2023-02-23 11:51:46,788 - pyskl - INFO - Epoch [15][20/94]	lr: 1.431e-01, eta: 0:04:50, time: 0.918, data_time: 0.762, memory: 861, top1_acc: 0.8063, top5_acc: 0.9953, loss_cls: 1.6050, loss: 1.6050, grad_norm: 1.6828
2023-02-23 11:51:50,424 - pyskl - INFO - Epoch [15][40/94]	lr: 1.378e-01, eta: 0:04:42, time: 0.182, data_time: 0.014, memory: 861, top1_acc: 0.8406, top5_acc: 0.9953, loss_cls: 1.2674, loss: 1.2674, grad_norm: 1.4369
2023-02-23 11:51:54,102 - pyskl - INFO - Epoch [15][60/94]	lr: 1.326e-01, eta: 0:04:34, time: 0.184, data_time: 0.020, memory: 861, top1_acc: 0.8187, top5_acc: 0.9938, loss_cls: 1.3819, loss: 1.3819, grad_norm: 1.6048
2023-02-23 11:51:57,743 - pyskl - INFO - Epoch [15][80/94]	lr: 1.273e-01, eta: 0:04:26, time: 0.182, data_time: 0.004, memory: 861, top1_acc: 0.8391, top5_acc: 0.9953, loss_cls: 1.2048, loss: 1.2048, grad_norm: 1.5176
2023-02-23 11:52:16,944 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:52:16,945 - pyskl - INFO - 
top1_acc	0.9800
top5_acc	1.0000
2023-02-23 11:52:16,945 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:52:16,945 - pyskl - INFO - 
mean_acc	0.9800
2023-02-23 11:52:16,945 - pyskl - INFO - Epoch(val) [15][4]	top1_acc: 0.9800, top5_acc: 1.0000, mean_class_accuracy: 0.9800
2023-02-23 11:52:34,846 - pyskl - INFO - Epoch [16][20/94]	lr: 1.186e-01, eta: 0:04:20, time: 0.895, data_time: 0.718, memory: 861, top1_acc: 0.8406, top5_acc: 0.9953, loss_cls: 1.2164, loss: 1.2164, grad_norm: 1.3878
2023-02-23 11:52:38,415 - pyskl - INFO - Epoch [16][40/94]	lr: 1.135e-01, eta: 0:04:12, time: 0.178, data_time: 0.001, memory: 861, top1_acc: 0.8469, top5_acc: 0.9969, loss_cls: 1.0797, loss: 1.0797, grad_norm: 1.4300
2023-02-23 11:52:41,933 - pyskl - INFO - Epoch [16][60/94]	lr: 1.086e-01, eta: 0:04:04, time: 0.176, data_time: 0.000, memory: 861, top1_acc: 0.8391, top5_acc: 0.9922, loss_cls: 1.0806, loss: 1.0806, grad_norm: 1.4051
2023-02-23 11:52:45,567 - pyskl - INFO - Epoch [16][80/94]	lr: 1.036e-01, eta: 0:03:57, time: 0.181, data_time: 0.000, memory: 861, top1_acc: 0.8391, top5_acc: 0.9969, loss_cls: 1.0799, loss: 1.0799, grad_norm: 1.3845
2023-02-23 11:53:04,445 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:53:04,445 - pyskl - INFO - 
top1_acc	0.9900
top5_acc	1.0000
2023-02-23 11:53:04,445 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:53:04,445 - pyskl - INFO - 
mean_acc	0.9900
2023-02-23 11:53:04,447 - pyskl - INFO - The previous best checkpoint /home/yl/sscls/model_pth/exp4/t5nsnr_wfwc/best_top1_acc_epoch_6.pth was removed
2023-02-23 11:53:04,472 - pyskl - INFO - Now best checkpoint is saved as best_top1_acc_epoch_16.pth.
2023-02-23 11:53:04,472 - pyskl - INFO - Best top1_acc is 0.9900 at 16 epoch.
2023-02-23 11:53:04,472 - pyskl - INFO - Epoch(val) [16][4]	top1_acc: 0.9900, top5_acc: 1.0000, mean_class_accuracy: 0.9900
2023-02-23 11:53:22,246 - pyskl - INFO - Epoch [17][20/94]	lr: 9.545e-02, eta: 0:03:50, time: 0.888, data_time: 0.840, memory: 861, top1_acc: 0.8500, top5_acc: 0.9984, loss_cls: 1.0908, loss: 1.0908, grad_norm: 1.3184
2023-02-23 11:53:25,964 - pyskl - INFO - Epoch [17][40/94]	lr: 9.075e-02, eta: 0:03:42, time: 0.186, data_time: 0.136, memory: 861, top1_acc: 0.8734, top5_acc: 1.0000, loss_cls: 0.7813, loss: 0.7813, grad_norm: 1.1849
2023-02-23 11:53:29,612 - pyskl - INFO - Epoch [17][60/94]	lr: 8.612e-02, eta: 0:03:35, time: 0.182, data_time: 0.131, memory: 861, top1_acc: 0.8500, top5_acc: 0.9984, loss_cls: 0.8830, loss: 0.8830, grad_norm: 1.3642
2023-02-23 11:53:33,463 - pyskl - INFO - Epoch [17][80/94]	lr: 8.159e-02, eta: 0:03:27, time: 0.192, data_time: 0.139, memory: 861, top1_acc: 0.8250, top5_acc: 0.9969, loss_cls: 0.9960, loss: 0.9960, grad_norm: 1.4736
2023-02-23 11:53:53,010 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:53:53,010 - pyskl - INFO - 
top1_acc	0.9900
top5_acc	1.0000
2023-02-23 11:53:53,010 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:53:53,011 - pyskl - INFO - 
mean_acc	0.9900
2023-02-23 11:53:53,011 - pyskl - INFO - Epoch(val) [17][4]	top1_acc: 0.9900, top5_acc: 1.0000, mean_class_accuracy: 0.9900
2023-02-23 11:54:11,169 - pyskl - INFO - Epoch [18][20/94]	lr: 7.409e-02, eta: 0:03:20, time: 0.908, data_time: 0.789, memory: 861, top1_acc: 0.8562, top5_acc: 0.9984, loss_cls: 1.0842, loss: 1.0842, grad_norm: 1.3913
2023-02-23 11:54:15,409 - pyskl - INFO - Epoch [18][40/94]	lr: 6.981e-02, eta: 0:03:13, time: 0.212, data_time: 0.023, memory: 861, top1_acc: 0.8719, top5_acc: 0.9969, loss_cls: 0.7422, loss: 0.7422, grad_norm: 1.3019
2023-02-23 11:54:19,077 - pyskl - INFO - Epoch [18][60/94]	lr: 6.564e-02, eta: 0:03:06, time: 0.183, data_time: 0.000, memory: 861, top1_acc: 0.8641, top5_acc: 0.9969, loss_cls: 0.7816, loss: 0.7816, grad_norm: 1.2557
2023-02-23 11:54:22,919 - pyskl - INFO - Epoch [18][80/94]	lr: 6.156e-02, eta: 0:02:59, time: 0.192, data_time: 0.015, memory: 861, top1_acc: 0.8516, top5_acc: 0.9984, loss_cls: 0.8935, loss: 0.8935, grad_norm: 1.3877
2023-02-23 11:54:41,708 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:54:41,709 - pyskl - INFO - 
top1_acc	0.9900
top5_acc	1.0000
2023-02-23 11:54:41,709 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:54:41,709 - pyskl - INFO - 
mean_acc	0.9900
2023-02-23 11:54:41,710 - pyskl - INFO - Epoch(val) [18][4]	top1_acc: 0.9900, top5_acc: 1.0000, mean_class_accuracy: 0.9900
2023-02-23 11:54:59,666 - pyskl - INFO - Epoch [19][20/94]	lr: 5.489e-02, eta: 0:02:50, time: 0.898, data_time: 0.827, memory: 861, top1_acc: 0.8734, top5_acc: 1.0000, loss_cls: 0.7516, loss: 0.7516, grad_norm: 1.2772
2023-02-23 11:55:03,223 - pyskl - INFO - Epoch [19][40/94]	lr: 5.111e-02, eta: 0:02:43, time: 0.178, data_time: 0.113, memory: 861, top1_acc: 0.8719, top5_acc: 0.9969, loss_cls: 0.8159, loss: 0.8159, grad_norm: 1.2188
2023-02-23 11:55:06,882 - pyskl - INFO - Epoch [19][60/94]	lr: 4.745e-02, eta: 0:02:36, time: 0.183, data_time: 0.102, memory: 861, top1_acc: 0.8859, top5_acc: 0.9984, loss_cls: 0.6482, loss: 0.6482, grad_norm: 1.1335
2023-02-23 11:55:10,509 - pyskl - INFO - Epoch [19][80/94]	lr: 4.391e-02, eta: 0:02:29, time: 0.181, data_time: 0.080, memory: 861, top1_acc: 0.8578, top5_acc: 0.9953, loss_cls: 0.8756, loss: 0.8756, grad_norm: 1.3114
2023-02-23 11:55:29,614 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:55:29,614 - pyskl - INFO - 
top1_acc	0.9900
top5_acc	1.0000
2023-02-23 11:55:29,614 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:55:29,615 - pyskl - INFO - 
mean_acc	0.9900
2023-02-23 11:55:29,615 - pyskl - INFO - Epoch(val) [19][4]	top1_acc: 0.9900, top5_acc: 1.0000, mean_class_accuracy: 0.9900
2023-02-23 11:55:47,590 - pyskl - INFO - Epoch [20][20/94]	lr: 3.816e-02, eta: 0:02:21, time: 0.899, data_time: 0.799, memory: 861, top1_acc: 0.8609, top5_acc: 0.9938, loss_cls: 0.8458, loss: 0.8458, grad_norm: 1.2185
2023-02-23 11:55:51,095 - pyskl - INFO - Epoch [20][40/94]	lr: 3.495e-02, eta: 0:02:14, time: 0.175, data_time: 0.104, memory: 861, top1_acc: 0.8703, top5_acc: 0.9953, loss_cls: 0.8127, loss: 0.8127, grad_norm: 1.2017
2023-02-23 11:55:54,661 - pyskl - INFO - Epoch [20][60/94]	lr: 3.187e-02, eta: 0:02:07, time: 0.178, data_time: 0.116, memory: 861, top1_acc: 0.8609, top5_acc: 0.9969, loss_cls: 0.8370, loss: 0.8370, grad_norm: 1.2917
2023-02-23 11:55:58,157 - pyskl - INFO - Epoch [20][80/94]	lr: 2.892e-02, eta: 0:02:00, time: 0.175, data_time: 0.099, memory: 861, top1_acc: 0.8797, top5_acc: 1.0000, loss_cls: 0.5618, loss: 0.5618, grad_norm: 1.1410
2023-02-23 11:56:20,271 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:56:20,272 - pyskl - INFO - 
top1_acc	0.9500
top5_acc	1.0000
2023-02-23 11:56:20,272 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:56:20,272 - pyskl - INFO - 
mean_acc	0.9500
2023-02-23 11:56:20,272 - pyskl - INFO - Epoch(val) [20][4]	top1_acc: 0.9500, top5_acc: 1.0000, mean_class_accuracy: 0.9500
2023-02-23 11:56:39,637 - pyskl - INFO - Epoch [21][20/94]	lr: 2.421e-02, eta: 0:01:51, time: 0.968, data_time: 0.759, memory: 861, top1_acc: 0.8703, top5_acc: 0.9984, loss_cls: 0.6629, loss: 0.6629, grad_norm: 1.2604
2023-02-23 11:56:43,190 - pyskl - INFO - Epoch [21][40/94]	lr: 2.162e-02, eta: 0:01:45, time: 0.178, data_time: 0.001, memory: 861, top1_acc: 0.8953, top5_acc: 0.9969, loss_cls: 0.5628, loss: 0.5628, grad_norm: 1.0684
2023-02-23 11:56:46,748 - pyskl - INFO - Epoch [21][60/94]	lr: 1.917e-02, eta: 0:01:38, time: 0.178, data_time: 0.000, memory: 861, top1_acc: 0.8938, top5_acc: 1.0000, loss_cls: 0.6569, loss: 0.6569, grad_norm: 1.0249
2023-02-23 11:56:50,313 - pyskl - INFO - Epoch [21][80/94]	lr: 1.686e-02, eta: 0:01:31, time: 0.178, data_time: 0.001, memory: 861, top1_acc: 0.8656, top5_acc: 1.0000, loss_cls: 0.6244, loss: 0.6244, grad_norm: 1.2629
2023-02-23 11:57:09,317 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:57:09,317 - pyskl - INFO - 
top1_acc	0.9900
top5_acc	1.0000
2023-02-23 11:57:09,317 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:57:09,318 - pyskl - INFO - 
mean_acc	0.9900
2023-02-23 11:57:09,318 - pyskl - INFO - Epoch(val) [21][4]	top1_acc: 0.9900, top5_acc: 1.0000, mean_class_accuracy: 0.9900
2023-02-23 11:57:27,342 - pyskl - INFO - Epoch [22][20/94]	lr: 1.326e-02, eta: 0:01:22, time: 0.901, data_time: 0.754, memory: 861, top1_acc: 0.8797, top5_acc: 0.9938, loss_cls: 0.5926, loss: 0.5926, grad_norm: 1.1843
2023-02-23 11:57:30,982 - pyskl - INFO - Epoch [22][40/94]	lr: 1.134e-02, eta: 0:01:15, time: 0.182, data_time: 0.005, memory: 861, top1_acc: 0.8641, top5_acc: 1.0000, loss_cls: 0.6896, loss: 0.6896, grad_norm: 1.2676
2023-02-23 11:57:34,670 - pyskl - INFO - Epoch [22][60/94]	lr: 9.566e-03, eta: 0:01:09, time: 0.184, data_time: 0.008, memory: 861, top1_acc: 0.8781, top5_acc: 1.0000, loss_cls: 0.6100, loss: 0.6100, grad_norm: 1.1983
2023-02-23 11:57:38,273 - pyskl - INFO - Epoch [22][80/94]	lr: 7.938e-03, eta: 0:01:02, time: 0.180, data_time: 0.002, memory: 861, top1_acc: 0.8984, top5_acc: 0.9969, loss_cls: 0.6142, loss: 0.6142, grad_norm: 1.0146
2023-02-23 11:57:57,144 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:57:57,144 - pyskl - INFO - 
top1_acc	0.9900
top5_acc	1.0000
2023-02-23 11:57:57,144 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:57:57,145 - pyskl - INFO - 
mean_acc	0.9900
2023-02-23 11:57:57,145 - pyskl - INFO - Epoch(val) [22][4]	top1_acc: 0.9900, top5_acc: 1.0000, mean_class_accuracy: 0.9900
2023-02-23 11:58:14,993 - pyskl - INFO - Epoch [23][20/94]	lr: 5.513e-03, eta: 0:00:52, time: 0.892, data_time: 0.786, memory: 861, top1_acc: 0.8797, top5_acc: 0.9969, loss_cls: 0.6238, loss: 0.6238, grad_norm: 1.1203
2023-02-23 11:58:18,594 - pyskl - INFO - Epoch [23][40/94]	lr: 4.290e-03, eta: 0:00:46, time: 0.180, data_time: 0.052, memory: 861, top1_acc: 0.8797, top5_acc: 0.9984, loss_cls: 0.6308, loss: 0.6308, grad_norm: 1.2082
2023-02-23 11:58:22,237 - pyskl - INFO - Epoch [23][60/94]	lr: 3.218e-03, eta: 0:00:39, time: 0.182, data_time: 0.022, memory: 861, top1_acc: 0.8719, top5_acc: 0.9984, loss_cls: 0.5572, loss: 0.5572, grad_norm: 1.2154
2023-02-23 11:58:25,837 - pyskl - INFO - Epoch [23][80/94]	lr: 2.300e-03, eta: 0:00:33, time: 0.180, data_time: 0.001, memory: 861, top1_acc: 0.8797, top5_acc: 0.9984, loss_cls: 0.5668, loss: 0.5668, grad_norm: 1.0991
2023-02-23 11:58:45,415 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:58:45,415 - pyskl - INFO - 
top1_acc	0.9900
top5_acc	1.0000
2023-02-23 11:58:45,415 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:58:45,416 - pyskl - INFO - 
mean_acc	0.9900
2023-02-23 11:58:45,416 - pyskl - INFO - Epoch(val) [23][4]	top1_acc: 0.9900, top5_acc: 1.0000, mean_class_accuracy: 0.9900
2023-02-23 11:59:03,319 - pyskl - INFO - Epoch [24][20/94]	lr: 1.090e-03, eta: 0:00:23, time: 0.895, data_time: 0.835, memory: 861, top1_acc: 0.9062, top5_acc: 1.0000, loss_cls: 0.4560, loss: 0.4560, grad_norm: 0.9834
2023-02-23 11:59:06,939 - pyskl - INFO - Epoch [24][40/94]	lr: 5.863e-04, eta: 0:00:16, time: 0.181, data_time: 0.122, memory: 861, top1_acc: 0.8828, top5_acc: 0.9984, loss_cls: 0.6841, loss: 0.6841, grad_norm: 1.1889
2023-02-23 11:59:10,715 - pyskl - INFO - Epoch [24][60/94]	lr: 2.375e-04, eta: 0:00:10, time: 0.189, data_time: 0.119, memory: 861, top1_acc: 0.8953, top5_acc: 0.9984, loss_cls: 0.5687, loss: 0.5687, grad_norm: 0.9650
2023-02-23 11:59:14,291 - pyskl - INFO - Epoch [24][80/94]	lr: 4.363e-05, eta: 0:00:04, time: 0.179, data_time: 0.123, memory: 861, top1_acc: 0.8953, top5_acc: 1.0000, loss_cls: 0.5619, loss: 0.5619, grad_norm: 1.0540
2023-02-23 11:59:17,470 - pyskl - INFO - Saving checkpoint at 24 epochs
2023-02-23 11:59:32,910 - pyskl - INFO - Evaluating top_k_accuracy ...
2023-02-23 11:59:32,910 - pyskl - INFO - 
top1_acc	0.9900
top5_acc	1.0000
2023-02-23 11:59:32,910 - pyskl - INFO - Evaluating mean_class_accuracy ...
2023-02-23 11:59:32,911 - pyskl - INFO - 
mean_acc	0.9900
2023-02-23 11:59:32,911 - pyskl - INFO - Epoch(val) [24][4]	top1_acc: 0.9900, top5_acc: 1.0000, mean_class_accuracy: 0.9900
